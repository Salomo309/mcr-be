{
  "best_global_step": 3862,
  "best_metric": 0.254821240901947,
  "best_model_checkpoint": "./codet5_lora_finetuned/checkpoint-3862",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 3862,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005178663904712584,
      "grad_norm": 5.4418463706970215,
      "learning_rate": 4.9935266701191095e-05,
      "loss": 3.1399,
      "step": 20
    },
    {
      "epoch": 0.010357327809425169,
      "grad_norm": 3.6615288257598877,
      "learning_rate": 4.986190229587434e-05,
      "loss": 2.0756,
      "step": 40
    },
    {
      "epoch": 0.015535991714137753,
      "grad_norm": 1.8053117990493774,
      "learning_rate": 4.977559123079579e-05,
      "loss": 1.3647,
      "step": 60
    },
    {
      "epoch": 0.020714655618850338,
      "grad_norm": 0.5942113995552063,
      "learning_rate": 4.968928016571724e-05,
      "loss": 1.2061,
      "step": 80
    },
    {
      "epoch": 0.02589331952356292,
      "grad_norm": 0.252359539270401,
      "learning_rate": 4.96029691006387e-05,
      "loss": 0.799,
      "step": 100
    },
    {
      "epoch": 0.031071983428275506,
      "grad_norm": 0.7699715495109558,
      "learning_rate": 4.951665803556016e-05,
      "loss": 0.7409,
      "step": 120
    },
    {
      "epoch": 0.03625064733298809,
      "grad_norm": 0.6522561311721802,
      "learning_rate": 4.9430346970481615e-05,
      "loss": 0.6315,
      "step": 140
    },
    {
      "epoch": 0.041429311237700675,
      "grad_norm": 0.347303181886673,
      "learning_rate": 4.9344035905403075e-05,
      "loss": 0.917,
      "step": 160
    },
    {
      "epoch": 0.04660797514241326,
      "grad_norm": 0.47506487369537354,
      "learning_rate": 4.9257724840324534e-05,
      "loss": 0.6321,
      "step": 180
    },
    {
      "epoch": 0.05178663904712584,
      "grad_norm": 0.5648607611656189,
      "learning_rate": 4.917141377524599e-05,
      "loss": 0.7177,
      "step": 200
    },
    {
      "epoch": 0.05696530295183842,
      "grad_norm": 1.6780266761779785,
      "learning_rate": 4.908510271016745e-05,
      "loss": 0.6122,
      "step": 220
    },
    {
      "epoch": 0.06214396685655101,
      "grad_norm": 0.2441677749156952,
      "learning_rate": 4.8998791645088906e-05,
      "loss": 0.7318,
      "step": 240
    },
    {
      "epoch": 0.06732263076126359,
      "grad_norm": 0.2859424948692322,
      "learning_rate": 4.891248058001036e-05,
      "loss": 0.4294,
      "step": 260
    },
    {
      "epoch": 0.07250129466597618,
      "grad_norm": 0.533876359462738,
      "learning_rate": 4.882616951493182e-05,
      "loss": 0.3694,
      "step": 280
    },
    {
      "epoch": 0.07767995857068877,
      "grad_norm": 0.23331330716609955,
      "learning_rate": 4.873985844985328e-05,
      "loss": 0.371,
      "step": 300
    },
    {
      "epoch": 0.08285862247540135,
      "grad_norm": 0.5662111043930054,
      "learning_rate": 4.865354738477473e-05,
      "loss": 0.3845,
      "step": 320
    },
    {
      "epoch": 0.08803728638011393,
      "grad_norm": 0.28147774934768677,
      "learning_rate": 4.8567236319696184e-05,
      "loss": 0.4682,
      "step": 340
    },
    {
      "epoch": 0.09321595028482652,
      "grad_norm": 0.7023089528083801,
      "learning_rate": 4.8480925254617644e-05,
      "loss": 0.3406,
      "step": 360
    },
    {
      "epoch": 0.0983946141895391,
      "grad_norm": 0.31658780574798584,
      "learning_rate": 4.83946141895391e-05,
      "loss": 0.4653,
      "step": 380
    },
    {
      "epoch": 0.10357327809425168,
      "grad_norm": 0.4099593162536621,
      "learning_rate": 4.8308303124460556e-05,
      "loss": 0.2863,
      "step": 400
    },
    {
      "epoch": 0.10875194199896426,
      "grad_norm": 0.41648033261299133,
      "learning_rate": 4.8221992059382015e-05,
      "loss": 0.3287,
      "step": 420
    },
    {
      "epoch": 0.11393060590367685,
      "grad_norm": 0.42797210812568665,
      "learning_rate": 4.8135680994303475e-05,
      "loss": 0.3441,
      "step": 440
    },
    {
      "epoch": 0.11910926980838944,
      "grad_norm": 0.5557637810707092,
      "learning_rate": 4.804936992922493e-05,
      "loss": 0.3596,
      "step": 460
    },
    {
      "epoch": 0.12428793371310203,
      "grad_norm": 6.235738277435303,
      "learning_rate": 4.796305886414639e-05,
      "loss": 0.7602,
      "step": 480
    },
    {
      "epoch": 0.1294665976178146,
      "grad_norm": 0.3186133801937103,
      "learning_rate": 4.787674779906785e-05,
      "loss": 0.3819,
      "step": 500
    },
    {
      "epoch": 0.13464526152252718,
      "grad_norm": 0.2662453055381775,
      "learning_rate": 4.77904367339893e-05,
      "loss": 0.3614,
      "step": 520
    },
    {
      "epoch": 0.13982392542723976,
      "grad_norm": 0.5363262295722961,
      "learning_rate": 4.770412566891075e-05,
      "loss": 0.2998,
      "step": 540
    },
    {
      "epoch": 0.14500258933195237,
      "grad_norm": 0.384355366230011,
      "learning_rate": 4.761781460383221e-05,
      "loss": 0.3446,
      "step": 560
    },
    {
      "epoch": 0.15018125323666495,
      "grad_norm": 0.6458573937416077,
      "learning_rate": 4.753150353875367e-05,
      "loss": 0.3404,
      "step": 580
    },
    {
      "epoch": 0.15535991714137753,
      "grad_norm": 0.6432197690010071,
      "learning_rate": 4.7445192473675125e-05,
      "loss": 0.3148,
      "step": 600
    },
    {
      "epoch": 0.16053858104609012,
      "grad_norm": 0.29082155227661133,
      "learning_rate": 4.7358881408596584e-05,
      "loss": 0.362,
      "step": 620
    },
    {
      "epoch": 0.1657172449508027,
      "grad_norm": 0.33055099844932556,
      "learning_rate": 4.7272570343518044e-05,
      "loss": 0.4391,
      "step": 640
    },
    {
      "epoch": 0.17089590885551528,
      "grad_norm": 0.7637268900871277,
      "learning_rate": 4.7186259278439496e-05,
      "loss": 0.3415,
      "step": 660
    },
    {
      "epoch": 0.17607457276022787,
      "grad_norm": 1.4779993295669556,
      "learning_rate": 4.7099948213360956e-05,
      "loss": 0.381,
      "step": 680
    },
    {
      "epoch": 0.18125323666494045,
      "grad_norm": 0.5152553915977478,
      "learning_rate": 4.7013637148282416e-05,
      "loss": 0.2908,
      "step": 700
    },
    {
      "epoch": 0.18643190056965303,
      "grad_norm": 0.26871180534362793,
      "learning_rate": 4.692732608320387e-05,
      "loss": 0.4119,
      "step": 720
    },
    {
      "epoch": 0.1916105644743656,
      "grad_norm": 0.5868985056877136,
      "learning_rate": 4.684101501812533e-05,
      "loss": 0.3946,
      "step": 740
    },
    {
      "epoch": 0.1967892283790782,
      "grad_norm": 0.5103040933609009,
      "learning_rate": 4.675470395304678e-05,
      "loss": 0.2111,
      "step": 760
    },
    {
      "epoch": 0.20196789228379078,
      "grad_norm": 1.0113095045089722,
      "learning_rate": 4.666839288796824e-05,
      "loss": 0.303,
      "step": 780
    },
    {
      "epoch": 0.20714655618850336,
      "grad_norm": 0.47185009717941284,
      "learning_rate": 4.658208182288969e-05,
      "loss": 0.2677,
      "step": 800
    },
    {
      "epoch": 0.21232522009321594,
      "grad_norm": 0.42445534467697144,
      "learning_rate": 4.649577075781115e-05,
      "loss": 0.323,
      "step": 820
    },
    {
      "epoch": 0.21750388399792853,
      "grad_norm": 1.3312263488769531,
      "learning_rate": 4.640945969273261e-05,
      "loss": 0.4778,
      "step": 840
    },
    {
      "epoch": 0.2226825479026411,
      "grad_norm": 0.7030391693115234,
      "learning_rate": 4.6323148627654065e-05,
      "loss": 0.3839,
      "step": 860
    },
    {
      "epoch": 0.2278612118073537,
      "grad_norm": 2.323596477508545,
      "learning_rate": 4.6236837562575525e-05,
      "loss": 0.3577,
      "step": 880
    },
    {
      "epoch": 0.23303987571206627,
      "grad_norm": 0.8864248991012573,
      "learning_rate": 4.6150526497496984e-05,
      "loss": 0.2524,
      "step": 900
    },
    {
      "epoch": 0.23821853961677888,
      "grad_norm": 0.2448681741952896,
      "learning_rate": 4.606421543241844e-05,
      "loss": 0.3743,
      "step": 920
    },
    {
      "epoch": 0.24339720352149147,
      "grad_norm": 0.18137586116790771,
      "learning_rate": 4.59779043673399e-05,
      "loss": 0.2704,
      "step": 940
    },
    {
      "epoch": 0.24857586742620405,
      "grad_norm": 0.22925706207752228,
      "learning_rate": 4.5891593302261356e-05,
      "loss": 0.4621,
      "step": 960
    },
    {
      "epoch": 0.25375453133091663,
      "grad_norm": 0.3992922008037567,
      "learning_rate": 4.580528223718281e-05,
      "loss": 0.4541,
      "step": 980
    },
    {
      "epoch": 0.2589331952356292,
      "grad_norm": 0.5338646769523621,
      "learning_rate": 4.571897117210426e-05,
      "loss": 0.1951,
      "step": 1000
    },
    {
      "epoch": 0.2641118591403418,
      "grad_norm": 0.16165930032730103,
      "learning_rate": 4.563266010702572e-05,
      "loss": 0.258,
      "step": 1020
    },
    {
      "epoch": 0.26929052304505435,
      "grad_norm": 0.4149869978427887,
      "learning_rate": 4.554634904194718e-05,
      "loss": 0.3759,
      "step": 1040
    },
    {
      "epoch": 0.27446918694976696,
      "grad_norm": 0.2524016201496124,
      "learning_rate": 4.5460037976868634e-05,
      "loss": 0.3403,
      "step": 1060
    },
    {
      "epoch": 0.2796478508544795,
      "grad_norm": 0.2906433641910553,
      "learning_rate": 4.537372691179009e-05,
      "loss": 0.2319,
      "step": 1080
    },
    {
      "epoch": 0.28482651475919213,
      "grad_norm": 1.2414487600326538,
      "learning_rate": 4.528741584671155e-05,
      "loss": 0.4094,
      "step": 1100
    },
    {
      "epoch": 0.29000517866390474,
      "grad_norm": 0.7795910239219666,
      "learning_rate": 4.5201104781633006e-05,
      "loss": 0.405,
      "step": 1120
    },
    {
      "epoch": 0.2951838425686173,
      "grad_norm": 0.6523194909095764,
      "learning_rate": 4.5114793716554465e-05,
      "loss": 0.2004,
      "step": 1140
    },
    {
      "epoch": 0.3003625064733299,
      "grad_norm": 0.38404878973960876,
      "learning_rate": 4.5028482651475925e-05,
      "loss": 0.2744,
      "step": 1160
    },
    {
      "epoch": 0.30554117037804246,
      "grad_norm": 0.21534408628940582,
      "learning_rate": 4.494217158639738e-05,
      "loss": 0.2707,
      "step": 1180
    },
    {
      "epoch": 0.31071983428275507,
      "grad_norm": 0.6847185492515564,
      "learning_rate": 4.485586052131884e-05,
      "loss": 0.199,
      "step": 1200
    },
    {
      "epoch": 0.3158984981874676,
      "grad_norm": 0.2447708696126938,
      "learning_rate": 4.476954945624029e-05,
      "loss": 0.4025,
      "step": 1220
    },
    {
      "epoch": 0.32107716209218023,
      "grad_norm": 2.386948347091675,
      "learning_rate": 4.468323839116175e-05,
      "loss": 0.2208,
      "step": 1240
    },
    {
      "epoch": 0.3262558259968928,
      "grad_norm": 0.6413496732711792,
      "learning_rate": 4.45969273260832e-05,
      "loss": 0.2532,
      "step": 1260
    },
    {
      "epoch": 0.3314344899016054,
      "grad_norm": 0.30791041254997253,
      "learning_rate": 4.451061626100466e-05,
      "loss": 0.2754,
      "step": 1280
    },
    {
      "epoch": 0.33661315380631796,
      "grad_norm": 0.5559980869293213,
      "learning_rate": 4.442430519592612e-05,
      "loss": 0.2665,
      "step": 1300
    },
    {
      "epoch": 0.34179181771103057,
      "grad_norm": 0.5964084267616272,
      "learning_rate": 4.4337994130847574e-05,
      "loss": 0.2523,
      "step": 1320
    },
    {
      "epoch": 0.3469704816157431,
      "grad_norm": 2.96209979057312,
      "learning_rate": 4.4251683065769034e-05,
      "loss": 0.3144,
      "step": 1340
    },
    {
      "epoch": 0.35214914552045573,
      "grad_norm": 0.36832597851753235,
      "learning_rate": 4.4165372000690494e-05,
      "loss": 0.3956,
      "step": 1360
    },
    {
      "epoch": 0.3573278094251683,
      "grad_norm": 4.451231002807617,
      "learning_rate": 4.4079060935611946e-05,
      "loss": 0.3544,
      "step": 1380
    },
    {
      "epoch": 0.3625064733298809,
      "grad_norm": 0.40332522988319397,
      "learning_rate": 4.3992749870533406e-05,
      "loss": 0.2304,
      "step": 1400
    },
    {
      "epoch": 0.36768513723459345,
      "grad_norm": 0.2975614368915558,
      "learning_rate": 4.3906438805454866e-05,
      "loss": 0.1815,
      "step": 1420
    },
    {
      "epoch": 0.37286380113930606,
      "grad_norm": 0.30432796478271484,
      "learning_rate": 4.382012774037632e-05,
      "loss": 0.4212,
      "step": 1440
    },
    {
      "epoch": 0.3780424650440186,
      "grad_norm": 0.40922942757606506,
      "learning_rate": 4.373381667529777e-05,
      "loss": 0.4094,
      "step": 1460
    },
    {
      "epoch": 0.3832211289487312,
      "grad_norm": 0.22560366988182068,
      "learning_rate": 4.364750561021923e-05,
      "loss": 0.3407,
      "step": 1480
    },
    {
      "epoch": 0.38839979285344384,
      "grad_norm": 0.5387113690376282,
      "learning_rate": 4.356119454514069e-05,
      "loss": 0.4131,
      "step": 1500
    },
    {
      "epoch": 0.3935784567581564,
      "grad_norm": 0.5973080396652222,
      "learning_rate": 4.347488348006214e-05,
      "loss": 0.3049,
      "step": 1520
    },
    {
      "epoch": 0.398757120662869,
      "grad_norm": 0.36984360218048096,
      "learning_rate": 4.33885724149836e-05,
      "loss": 0.4282,
      "step": 1540
    },
    {
      "epoch": 0.40393578456758156,
      "grad_norm": 0.43832510709762573,
      "learning_rate": 4.330226134990506e-05,
      "loss": 0.3696,
      "step": 1560
    },
    {
      "epoch": 0.40911444847229417,
      "grad_norm": 0.2445806860923767,
      "learning_rate": 4.3215950284826515e-05,
      "loss": 0.5044,
      "step": 1580
    },
    {
      "epoch": 0.4142931123770067,
      "grad_norm": 0.3528139591217041,
      "learning_rate": 4.3129639219747975e-05,
      "loss": 0.3842,
      "step": 1600
    },
    {
      "epoch": 0.41947177628171933,
      "grad_norm": 0.23381169140338898,
      "learning_rate": 4.3043328154669434e-05,
      "loss": 0.2601,
      "step": 1620
    },
    {
      "epoch": 0.4246504401864319,
      "grad_norm": 0.34920090436935425,
      "learning_rate": 4.295701708959089e-05,
      "loss": 0.4185,
      "step": 1640
    },
    {
      "epoch": 0.4298291040911445,
      "grad_norm": 0.3530692756175995,
      "learning_rate": 4.2870706024512347e-05,
      "loss": 0.3769,
      "step": 1660
    },
    {
      "epoch": 0.43500776799585705,
      "grad_norm": 0.221157968044281,
      "learning_rate": 4.27843949594338e-05,
      "loss": 0.1591,
      "step": 1680
    },
    {
      "epoch": 0.44018643190056966,
      "grad_norm": 0.4736630320549011,
      "learning_rate": 4.269808389435526e-05,
      "loss": 0.2705,
      "step": 1700
    },
    {
      "epoch": 0.4453650958052822,
      "grad_norm": 0.23429280519485474,
      "learning_rate": 4.261177282927671e-05,
      "loss": 0.3141,
      "step": 1720
    },
    {
      "epoch": 0.45054375970999483,
      "grad_norm": 0.4009598195552826,
      "learning_rate": 4.252546176419817e-05,
      "loss": 0.3532,
      "step": 1740
    },
    {
      "epoch": 0.4557224236147074,
      "grad_norm": 0.5748755931854248,
      "learning_rate": 4.243915069911963e-05,
      "loss": 0.2976,
      "step": 1760
    },
    {
      "epoch": 0.46090108751942,
      "grad_norm": 0.9929515719413757,
      "learning_rate": 4.2352839634041084e-05,
      "loss": 0.207,
      "step": 1780
    },
    {
      "epoch": 0.46607975142413255,
      "grad_norm": 0.613699734210968,
      "learning_rate": 4.226652856896254e-05,
      "loss": 0.322,
      "step": 1800
    },
    {
      "epoch": 0.47125841532884516,
      "grad_norm": 0.4945605397224426,
      "learning_rate": 4.2180217503884e-05,
      "loss": 0.3985,
      "step": 1820
    },
    {
      "epoch": 0.47643707923355777,
      "grad_norm": 0.2929111123085022,
      "learning_rate": 4.2093906438805456e-05,
      "loss": 0.3098,
      "step": 1840
    },
    {
      "epoch": 0.4816157431382703,
      "grad_norm": 0.23231986165046692,
      "learning_rate": 4.2007595373726915e-05,
      "loss": 0.3984,
      "step": 1860
    },
    {
      "epoch": 0.48679440704298294,
      "grad_norm": 0.2671286165714264,
      "learning_rate": 4.1921284308648375e-05,
      "loss": 0.3078,
      "step": 1880
    },
    {
      "epoch": 0.4919730709476955,
      "grad_norm": 0.7535843849182129,
      "learning_rate": 4.183497324356983e-05,
      "loss": 0.202,
      "step": 1900
    },
    {
      "epoch": 0.4971517348524081,
      "grad_norm": 0.6174108386039734,
      "learning_rate": 4.174866217849128e-05,
      "loss": 0.4872,
      "step": 1920
    },
    {
      "epoch": 0.5023303987571207,
      "grad_norm": 0.7214367985725403,
      "learning_rate": 4.166235111341274e-05,
      "loss": 0.2632,
      "step": 1940
    },
    {
      "epoch": 0.5075090626618333,
      "grad_norm": 0.43288886547088623,
      "learning_rate": 4.15760400483342e-05,
      "loss": 0.254,
      "step": 1960
    },
    {
      "epoch": 0.5126877265665458,
      "grad_norm": 0.23964056372642517,
      "learning_rate": 4.148972898325565e-05,
      "loss": 0.257,
      "step": 1980
    },
    {
      "epoch": 0.5178663904712584,
      "grad_norm": 0.2910713851451874,
      "learning_rate": 4.140341791817711e-05,
      "loss": 0.4849,
      "step": 2000
    },
    {
      "epoch": 0.523045054375971,
      "grad_norm": 0.3571830689907074,
      "learning_rate": 4.131710685309857e-05,
      "loss": 0.4354,
      "step": 2020
    },
    {
      "epoch": 0.5282237182806836,
      "grad_norm": 0.17866720259189606,
      "learning_rate": 4.1230795788020024e-05,
      "loss": 0.2375,
      "step": 2040
    },
    {
      "epoch": 0.5334023821853962,
      "grad_norm": 0.28448501229286194,
      "learning_rate": 4.1144484722941484e-05,
      "loss": 0.3183,
      "step": 2060
    },
    {
      "epoch": 0.5385810460901087,
      "grad_norm": 0.3942638039588928,
      "learning_rate": 4.1058173657862943e-05,
      "loss": 0.418,
      "step": 2080
    },
    {
      "epoch": 0.5437597099948214,
      "grad_norm": 0.7856264710426331,
      "learning_rate": 4.0971862592784396e-05,
      "loss": 0.2423,
      "step": 2100
    },
    {
      "epoch": 0.5489383738995339,
      "grad_norm": 0.6947046518325806,
      "learning_rate": 4.0885551527705856e-05,
      "loss": 0.3978,
      "step": 2120
    },
    {
      "epoch": 0.5541170378042465,
      "grad_norm": 0.3705627918243408,
      "learning_rate": 4.079924046262731e-05,
      "loss": 0.3006,
      "step": 2140
    },
    {
      "epoch": 0.559295701708959,
      "grad_norm": 0.6691087484359741,
      "learning_rate": 4.071292939754877e-05,
      "loss": 0.4198,
      "step": 2160
    },
    {
      "epoch": 0.5644743656136717,
      "grad_norm": 0.5391852855682373,
      "learning_rate": 4.062661833247022e-05,
      "loss": 0.2998,
      "step": 2180
    },
    {
      "epoch": 0.5696530295183843,
      "grad_norm": 0.7486177682876587,
      "learning_rate": 4.054030726739168e-05,
      "loss": 0.2204,
      "step": 2200
    },
    {
      "epoch": 0.5748316934230968,
      "grad_norm": 0.1917324811220169,
      "learning_rate": 4.045399620231314e-05,
      "loss": 0.2013,
      "step": 2220
    },
    {
      "epoch": 0.5800103573278095,
      "grad_norm": 0.3394862711429596,
      "learning_rate": 4.036768513723459e-05,
      "loss": 0.2894,
      "step": 2240
    },
    {
      "epoch": 0.585189021232522,
      "grad_norm": 0.287281334400177,
      "learning_rate": 4.028137407215605e-05,
      "loss": 0.4047,
      "step": 2260
    },
    {
      "epoch": 0.5903676851372346,
      "grad_norm": 0.4311116337776184,
      "learning_rate": 4.019506300707751e-05,
      "loss": 0.2799,
      "step": 2280
    },
    {
      "epoch": 0.5955463490419471,
      "grad_norm": 1.2925471067428589,
      "learning_rate": 4.0108751941998965e-05,
      "loss": 0.2655,
      "step": 2300
    },
    {
      "epoch": 0.6007250129466598,
      "grad_norm": 0.1832837015390396,
      "learning_rate": 4.0022440876920424e-05,
      "loss": 0.4018,
      "step": 2320
    },
    {
      "epoch": 0.6059036768513724,
      "grad_norm": 0.3604970872402191,
      "learning_rate": 3.9936129811841884e-05,
      "loss": 0.5057,
      "step": 2340
    },
    {
      "epoch": 0.6110823407560849,
      "grad_norm": 0.28133347630500793,
      "learning_rate": 3.984981874676334e-05,
      "loss": 0.2671,
      "step": 2360
    },
    {
      "epoch": 0.6162610046607975,
      "grad_norm": 0.6586342453956604,
      "learning_rate": 3.976350768168479e-05,
      "loss": 0.5012,
      "step": 2380
    },
    {
      "epoch": 0.6214396685655101,
      "grad_norm": 0.49067237973213196,
      "learning_rate": 3.967719661660625e-05,
      "loss": 0.2996,
      "step": 2400
    },
    {
      "epoch": 0.6266183324702227,
      "grad_norm": 0.4012816250324249,
      "learning_rate": 3.959088555152771e-05,
      "loss": 0.2418,
      "step": 2420
    },
    {
      "epoch": 0.6317969963749352,
      "grad_norm": 0.27531805634498596,
      "learning_rate": 3.950457448644916e-05,
      "loss": 0.2332,
      "step": 2440
    },
    {
      "epoch": 0.6369756602796478,
      "grad_norm": 1.5769098997116089,
      "learning_rate": 3.941826342137062e-05,
      "loss": 0.433,
      "step": 2460
    },
    {
      "epoch": 0.6421543241843605,
      "grad_norm": 0.4245220422744751,
      "learning_rate": 3.933195235629208e-05,
      "loss": 0.2843,
      "step": 2480
    },
    {
      "epoch": 0.647332988089073,
      "grad_norm": 0.24415987730026245,
      "learning_rate": 3.9245641291213534e-05,
      "loss": 0.2708,
      "step": 2500
    },
    {
      "epoch": 0.6525116519937856,
      "grad_norm": 0.17765936255455017,
      "learning_rate": 3.915933022613499e-05,
      "loss": 0.2521,
      "step": 2520
    },
    {
      "epoch": 0.6576903158984981,
      "grad_norm": 1.2618598937988281,
      "learning_rate": 3.907301916105645e-05,
      "loss": 0.296,
      "step": 2540
    },
    {
      "epoch": 0.6628689798032108,
      "grad_norm": 0.32594192028045654,
      "learning_rate": 3.8986708095977905e-05,
      "loss": 0.1783,
      "step": 2560
    },
    {
      "epoch": 0.6680476437079234,
      "grad_norm": 0.8046995997428894,
      "learning_rate": 3.8900397030899365e-05,
      "loss": 0.3756,
      "step": 2580
    },
    {
      "epoch": 0.6732263076126359,
      "grad_norm": 0.48054957389831543,
      "learning_rate": 3.881408596582082e-05,
      "loss": 0.2136,
      "step": 2600
    },
    {
      "epoch": 0.6784049715173486,
      "grad_norm": 0.5415575504302979,
      "learning_rate": 3.872777490074228e-05,
      "loss": 0.3006,
      "step": 2620
    },
    {
      "epoch": 0.6835836354220611,
      "grad_norm": 2.0498526096343994,
      "learning_rate": 3.864146383566373e-05,
      "loss": 0.2425,
      "step": 2640
    },
    {
      "epoch": 0.6887622993267737,
      "grad_norm": 0.2906571328639984,
      "learning_rate": 3.855515277058519e-05,
      "loss": 0.1982,
      "step": 2660
    },
    {
      "epoch": 0.6939409632314862,
      "grad_norm": 0.3364759683609009,
      "learning_rate": 3.846884170550665e-05,
      "loss": 0.2315,
      "step": 2680
    },
    {
      "epoch": 0.6991196271361989,
      "grad_norm": 0.2905983328819275,
      "learning_rate": 3.83825306404281e-05,
      "loss": 0.1992,
      "step": 2700
    },
    {
      "epoch": 0.7042982910409115,
      "grad_norm": 1.0067291259765625,
      "learning_rate": 3.829621957534956e-05,
      "loss": 0.2553,
      "step": 2720
    },
    {
      "epoch": 0.709476954945624,
      "grad_norm": 0.2728920578956604,
      "learning_rate": 3.820990851027102e-05,
      "loss": 0.3135,
      "step": 2740
    },
    {
      "epoch": 0.7146556188503366,
      "grad_norm": 0.9197738170623779,
      "learning_rate": 3.8123597445192474e-05,
      "loss": 0.2683,
      "step": 2760
    },
    {
      "epoch": 0.7198342827550492,
      "grad_norm": 0.5005480647087097,
      "learning_rate": 3.8037286380113934e-05,
      "loss": 0.2514,
      "step": 2780
    },
    {
      "epoch": 0.7250129466597618,
      "grad_norm": 0.6712875366210938,
      "learning_rate": 3.795097531503539e-05,
      "loss": 0.2957,
      "step": 2800
    },
    {
      "epoch": 0.7301916105644743,
      "grad_norm": 0.2787967324256897,
      "learning_rate": 3.7864664249956846e-05,
      "loss": 0.3263,
      "step": 2820
    },
    {
      "epoch": 0.7353702744691869,
      "grad_norm": 0.601595938205719,
      "learning_rate": 3.77783531848783e-05,
      "loss": 0.2674,
      "step": 2840
    },
    {
      "epoch": 0.7405489383738996,
      "grad_norm": 0.7207546234130859,
      "learning_rate": 3.769204211979976e-05,
      "loss": 0.3049,
      "step": 2860
    },
    {
      "epoch": 0.7457276022786121,
      "grad_norm": 0.1487516462802887,
      "learning_rate": 3.760573105472122e-05,
      "loss": 0.2199,
      "step": 2880
    },
    {
      "epoch": 0.7509062661833247,
      "grad_norm": 0.19878032803535461,
      "learning_rate": 3.751941998964267e-05,
      "loss": 0.1885,
      "step": 2900
    },
    {
      "epoch": 0.7560849300880372,
      "grad_norm": 0.18069666624069214,
      "learning_rate": 3.743310892456413e-05,
      "loss": 0.3924,
      "step": 2920
    },
    {
      "epoch": 0.7612635939927499,
      "grad_norm": 0.2777796685695648,
      "learning_rate": 3.734679785948559e-05,
      "loss": 0.2324,
      "step": 2940
    },
    {
      "epoch": 0.7664422578974625,
      "grad_norm": 0.49304449558258057,
      "learning_rate": 3.726048679440704e-05,
      "loss": 0.3915,
      "step": 2960
    },
    {
      "epoch": 0.771620921802175,
      "grad_norm": 0.1731625348329544,
      "learning_rate": 3.71741757293285e-05,
      "loss": 0.1408,
      "step": 2980
    },
    {
      "epoch": 0.7767995857068877,
      "grad_norm": 0.37605467438697815,
      "learning_rate": 3.708786466424996e-05,
      "loss": 0.2196,
      "step": 3000
    },
    {
      "epoch": 0.7819782496116002,
      "grad_norm": 0.26363804936408997,
      "learning_rate": 3.7001553599171415e-05,
      "loss": 0.2876,
      "step": 3020
    },
    {
      "epoch": 0.7871569135163128,
      "grad_norm": 0.5399924516677856,
      "learning_rate": 3.691524253409287e-05,
      "loss": 0.2097,
      "step": 3040
    },
    {
      "epoch": 0.7923355774210253,
      "grad_norm": 0.750304639339447,
      "learning_rate": 3.682893146901433e-05,
      "loss": 0.3571,
      "step": 3060
    },
    {
      "epoch": 0.797514241325738,
      "grad_norm": 0.3860228657722473,
      "learning_rate": 3.674262040393579e-05,
      "loss": 0.3671,
      "step": 3080
    },
    {
      "epoch": 0.8026929052304506,
      "grad_norm": 0.382425457239151,
      "learning_rate": 3.665630933885724e-05,
      "loss": 0.2678,
      "step": 3100
    },
    {
      "epoch": 0.8078715691351631,
      "grad_norm": 90.97516632080078,
      "learning_rate": 3.65699982737787e-05,
      "loss": 0.2089,
      "step": 3120
    },
    {
      "epoch": 0.8130502330398757,
      "grad_norm": 0.753862738609314,
      "learning_rate": 3.648368720870016e-05,
      "loss": 0.3125,
      "step": 3140
    },
    {
      "epoch": 0.8182288969445883,
      "grad_norm": 0.4268838167190552,
      "learning_rate": 3.639737614362161e-05,
      "loss": 0.1657,
      "step": 3160
    },
    {
      "epoch": 0.8234075608493009,
      "grad_norm": 0.3272823393344879,
      "learning_rate": 3.631106507854307e-05,
      "loss": 0.3648,
      "step": 3180
    },
    {
      "epoch": 0.8285862247540134,
      "grad_norm": 0.15284357964992523,
      "learning_rate": 3.622475401346453e-05,
      "loss": 0.2082,
      "step": 3200
    },
    {
      "epoch": 0.833764888658726,
      "grad_norm": 0.14540927112102509,
      "learning_rate": 3.6138442948385983e-05,
      "loss": 0.2249,
      "step": 3220
    },
    {
      "epoch": 0.8389435525634387,
      "grad_norm": 0.28681761026382446,
      "learning_rate": 3.605213188330744e-05,
      "loss": 0.3839,
      "step": 3240
    },
    {
      "epoch": 0.8441222164681512,
      "grad_norm": 0.23126360774040222,
      "learning_rate": 3.59658208182289e-05,
      "loss": 0.3072,
      "step": 3260
    },
    {
      "epoch": 0.8493008803728638,
      "grad_norm": 0.16833344101905823,
      "learning_rate": 3.5879509753150355e-05,
      "loss": 0.5178,
      "step": 3280
    },
    {
      "epoch": 0.8544795442775763,
      "grad_norm": 0.5017094612121582,
      "learning_rate": 3.579319868807181e-05,
      "loss": 0.2528,
      "step": 3300
    },
    {
      "epoch": 0.859658208182289,
      "grad_norm": 0.6041623950004578,
      "learning_rate": 3.570688762299327e-05,
      "loss": 0.3182,
      "step": 3320
    },
    {
      "epoch": 0.8648368720870016,
      "grad_norm": 0.37381231784820557,
      "learning_rate": 3.562057655791473e-05,
      "loss": 0.304,
      "step": 3340
    },
    {
      "epoch": 0.8700155359917141,
      "grad_norm": 0.47815319895744324,
      "learning_rate": 3.553426549283618e-05,
      "loss": 0.2498,
      "step": 3360
    },
    {
      "epoch": 0.8751941998964268,
      "grad_norm": 0.6863347291946411,
      "learning_rate": 3.544795442775764e-05,
      "loss": 0.2666,
      "step": 3380
    },
    {
      "epoch": 0.8803728638011393,
      "grad_norm": 0.38463932275772095,
      "learning_rate": 3.53616433626791e-05,
      "loss": 0.2579,
      "step": 3400
    },
    {
      "epoch": 0.8855515277058519,
      "grad_norm": 0.49278998374938965,
      "learning_rate": 3.527533229760055e-05,
      "loss": 0.2437,
      "step": 3420
    },
    {
      "epoch": 0.8907301916105644,
      "grad_norm": 0.2010909467935562,
      "learning_rate": 3.518902123252201e-05,
      "loss": 0.3184,
      "step": 3440
    },
    {
      "epoch": 0.8959088555152771,
      "grad_norm": 0.4222787022590637,
      "learning_rate": 3.510271016744347e-05,
      "loss": 0.2037,
      "step": 3460
    },
    {
      "epoch": 0.9010875194199897,
      "grad_norm": 0.9825772047042847,
      "learning_rate": 3.5016399102364924e-05,
      "loss": 0.2155,
      "step": 3480
    },
    {
      "epoch": 0.9062661833247022,
      "grad_norm": 0.6194919943809509,
      "learning_rate": 3.493008803728638e-05,
      "loss": 0.2684,
      "step": 3500
    },
    {
      "epoch": 0.9114448472294148,
      "grad_norm": 0.5779101252555847,
      "learning_rate": 3.4843776972207836e-05,
      "loss": 0.2513,
      "step": 3520
    },
    {
      "epoch": 0.9166235111341274,
      "grad_norm": 0.19147661328315735,
      "learning_rate": 3.4757465907129296e-05,
      "loss": 0.1901,
      "step": 3540
    },
    {
      "epoch": 0.92180217503884,
      "grad_norm": 0.18686838448047638,
      "learning_rate": 3.467115484205075e-05,
      "loss": 0.3113,
      "step": 3560
    },
    {
      "epoch": 0.9269808389435525,
      "grad_norm": 0.3124150335788727,
      "learning_rate": 3.458484377697221e-05,
      "loss": 0.2878,
      "step": 3580
    },
    {
      "epoch": 0.9321595028482651,
      "grad_norm": 1.5176973342895508,
      "learning_rate": 3.449853271189367e-05,
      "loss": 0.2897,
      "step": 3600
    },
    {
      "epoch": 0.9373381667529778,
      "grad_norm": 0.25537213683128357,
      "learning_rate": 3.441222164681512e-05,
      "loss": 0.3078,
      "step": 3620
    },
    {
      "epoch": 0.9425168306576903,
      "grad_norm": 1.023582935333252,
      "learning_rate": 3.432591058173658e-05,
      "loss": 0.3669,
      "step": 3640
    },
    {
      "epoch": 0.9476954945624029,
      "grad_norm": 2.9341962337493896,
      "learning_rate": 3.423959951665804e-05,
      "loss": 0.2058,
      "step": 3660
    },
    {
      "epoch": 0.9528741584671155,
      "grad_norm": 0.5623692870140076,
      "learning_rate": 3.415328845157949e-05,
      "loss": 0.3388,
      "step": 3680
    },
    {
      "epoch": 0.9580528223718281,
      "grad_norm": 0.7481259107589722,
      "learning_rate": 3.406697738650095e-05,
      "loss": 0.2374,
      "step": 3700
    },
    {
      "epoch": 0.9632314862765406,
      "grad_norm": 0.41873887181282043,
      "learning_rate": 3.3980666321422405e-05,
      "loss": 0.2154,
      "step": 3720
    },
    {
      "epoch": 0.9684101501812532,
      "grad_norm": 0.2509080469608307,
      "learning_rate": 3.3894355256343865e-05,
      "loss": 0.2517,
      "step": 3740
    },
    {
      "epoch": 0.9735888140859659,
      "grad_norm": 0.14607271552085876,
      "learning_rate": 3.380804419126532e-05,
      "loss": 0.3121,
      "step": 3760
    },
    {
      "epoch": 0.9787674779906784,
      "grad_norm": 0.6303099393844604,
      "learning_rate": 3.372173312618678e-05,
      "loss": 0.2354,
      "step": 3780
    },
    {
      "epoch": 0.983946141895391,
      "grad_norm": 0.23458294570446014,
      "learning_rate": 3.3635422061108237e-05,
      "loss": 0.4003,
      "step": 3800
    },
    {
      "epoch": 0.9891248058001035,
      "grad_norm": 0.22983191907405853,
      "learning_rate": 3.354911099602969e-05,
      "loss": 0.374,
      "step": 3820
    },
    {
      "epoch": 0.9943034697048162,
      "grad_norm": 0.2524656355381012,
      "learning_rate": 3.346279993095115e-05,
      "loss": 0.1468,
      "step": 3840
    },
    {
      "epoch": 0.9994821336095288,
      "grad_norm": 0.884723961353302,
      "learning_rate": 3.337648886587261e-05,
      "loss": 0.3482,
      "step": 3860
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.254821240901947,
      "eval_runtime": 31.2697,
      "eval_samples_per_second": 27.471,
      "eval_steps_per_second": 3.454,
      "step": 3862
    }
  ],
  "logging_steps": 20,
  "max_steps": 11586,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4744962611085312.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
