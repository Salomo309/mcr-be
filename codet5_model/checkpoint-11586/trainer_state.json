{
  "best_global_step": 11586,
  "best_metric": 0.24323676526546478,
  "best_model_checkpoint": "./codet5_lora_finetuned/checkpoint-11586",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 11586,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005178663904712584,
      "grad_norm": 5.4418463706970215,
      "learning_rate": 4.9935266701191095e-05,
      "loss": 3.1399,
      "step": 20
    },
    {
      "epoch": 0.010357327809425169,
      "grad_norm": 3.6615288257598877,
      "learning_rate": 4.986190229587434e-05,
      "loss": 2.0756,
      "step": 40
    },
    {
      "epoch": 0.015535991714137753,
      "grad_norm": 1.8053117990493774,
      "learning_rate": 4.977559123079579e-05,
      "loss": 1.3647,
      "step": 60
    },
    {
      "epoch": 0.020714655618850338,
      "grad_norm": 0.5942113995552063,
      "learning_rate": 4.968928016571724e-05,
      "loss": 1.2061,
      "step": 80
    },
    {
      "epoch": 0.02589331952356292,
      "grad_norm": 0.252359539270401,
      "learning_rate": 4.96029691006387e-05,
      "loss": 0.799,
      "step": 100
    },
    {
      "epoch": 0.031071983428275506,
      "grad_norm": 0.7699715495109558,
      "learning_rate": 4.951665803556016e-05,
      "loss": 0.7409,
      "step": 120
    },
    {
      "epoch": 0.03625064733298809,
      "grad_norm": 0.6522561311721802,
      "learning_rate": 4.9430346970481615e-05,
      "loss": 0.6315,
      "step": 140
    },
    {
      "epoch": 0.041429311237700675,
      "grad_norm": 0.347303181886673,
      "learning_rate": 4.9344035905403075e-05,
      "loss": 0.917,
      "step": 160
    },
    {
      "epoch": 0.04660797514241326,
      "grad_norm": 0.47506487369537354,
      "learning_rate": 4.9257724840324534e-05,
      "loss": 0.6321,
      "step": 180
    },
    {
      "epoch": 0.05178663904712584,
      "grad_norm": 0.5648607611656189,
      "learning_rate": 4.917141377524599e-05,
      "loss": 0.7177,
      "step": 200
    },
    {
      "epoch": 0.05696530295183842,
      "grad_norm": 1.6780266761779785,
      "learning_rate": 4.908510271016745e-05,
      "loss": 0.6122,
      "step": 220
    },
    {
      "epoch": 0.06214396685655101,
      "grad_norm": 0.2441677749156952,
      "learning_rate": 4.8998791645088906e-05,
      "loss": 0.7318,
      "step": 240
    },
    {
      "epoch": 0.06732263076126359,
      "grad_norm": 0.2859424948692322,
      "learning_rate": 4.891248058001036e-05,
      "loss": 0.4294,
      "step": 260
    },
    {
      "epoch": 0.07250129466597618,
      "grad_norm": 0.533876359462738,
      "learning_rate": 4.882616951493182e-05,
      "loss": 0.3694,
      "step": 280
    },
    {
      "epoch": 0.07767995857068877,
      "grad_norm": 0.23331330716609955,
      "learning_rate": 4.873985844985328e-05,
      "loss": 0.371,
      "step": 300
    },
    {
      "epoch": 0.08285862247540135,
      "grad_norm": 0.5662111043930054,
      "learning_rate": 4.865354738477473e-05,
      "loss": 0.3845,
      "step": 320
    },
    {
      "epoch": 0.08803728638011393,
      "grad_norm": 0.28147774934768677,
      "learning_rate": 4.8567236319696184e-05,
      "loss": 0.4682,
      "step": 340
    },
    {
      "epoch": 0.09321595028482652,
      "grad_norm": 0.7023089528083801,
      "learning_rate": 4.8480925254617644e-05,
      "loss": 0.3406,
      "step": 360
    },
    {
      "epoch": 0.0983946141895391,
      "grad_norm": 0.31658780574798584,
      "learning_rate": 4.83946141895391e-05,
      "loss": 0.4653,
      "step": 380
    },
    {
      "epoch": 0.10357327809425168,
      "grad_norm": 0.4099593162536621,
      "learning_rate": 4.8308303124460556e-05,
      "loss": 0.2863,
      "step": 400
    },
    {
      "epoch": 0.10875194199896426,
      "grad_norm": 0.41648033261299133,
      "learning_rate": 4.8221992059382015e-05,
      "loss": 0.3287,
      "step": 420
    },
    {
      "epoch": 0.11393060590367685,
      "grad_norm": 0.42797210812568665,
      "learning_rate": 4.8135680994303475e-05,
      "loss": 0.3441,
      "step": 440
    },
    {
      "epoch": 0.11910926980838944,
      "grad_norm": 0.5557637810707092,
      "learning_rate": 4.804936992922493e-05,
      "loss": 0.3596,
      "step": 460
    },
    {
      "epoch": 0.12428793371310203,
      "grad_norm": 6.235738277435303,
      "learning_rate": 4.796305886414639e-05,
      "loss": 0.7602,
      "step": 480
    },
    {
      "epoch": 0.1294665976178146,
      "grad_norm": 0.3186133801937103,
      "learning_rate": 4.787674779906785e-05,
      "loss": 0.3819,
      "step": 500
    },
    {
      "epoch": 0.13464526152252718,
      "grad_norm": 0.2662453055381775,
      "learning_rate": 4.77904367339893e-05,
      "loss": 0.3614,
      "step": 520
    },
    {
      "epoch": 0.13982392542723976,
      "grad_norm": 0.5363262295722961,
      "learning_rate": 4.770412566891075e-05,
      "loss": 0.2998,
      "step": 540
    },
    {
      "epoch": 0.14500258933195237,
      "grad_norm": 0.384355366230011,
      "learning_rate": 4.761781460383221e-05,
      "loss": 0.3446,
      "step": 560
    },
    {
      "epoch": 0.15018125323666495,
      "grad_norm": 0.6458573937416077,
      "learning_rate": 4.753150353875367e-05,
      "loss": 0.3404,
      "step": 580
    },
    {
      "epoch": 0.15535991714137753,
      "grad_norm": 0.6432197690010071,
      "learning_rate": 4.7445192473675125e-05,
      "loss": 0.3148,
      "step": 600
    },
    {
      "epoch": 0.16053858104609012,
      "grad_norm": 0.29082155227661133,
      "learning_rate": 4.7358881408596584e-05,
      "loss": 0.362,
      "step": 620
    },
    {
      "epoch": 0.1657172449508027,
      "grad_norm": 0.33055099844932556,
      "learning_rate": 4.7272570343518044e-05,
      "loss": 0.4391,
      "step": 640
    },
    {
      "epoch": 0.17089590885551528,
      "grad_norm": 0.7637268900871277,
      "learning_rate": 4.7186259278439496e-05,
      "loss": 0.3415,
      "step": 660
    },
    {
      "epoch": 0.17607457276022787,
      "grad_norm": 1.4779993295669556,
      "learning_rate": 4.7099948213360956e-05,
      "loss": 0.381,
      "step": 680
    },
    {
      "epoch": 0.18125323666494045,
      "grad_norm": 0.5152553915977478,
      "learning_rate": 4.7013637148282416e-05,
      "loss": 0.2908,
      "step": 700
    },
    {
      "epoch": 0.18643190056965303,
      "grad_norm": 0.26871180534362793,
      "learning_rate": 4.692732608320387e-05,
      "loss": 0.4119,
      "step": 720
    },
    {
      "epoch": 0.1916105644743656,
      "grad_norm": 0.5868985056877136,
      "learning_rate": 4.684101501812533e-05,
      "loss": 0.3946,
      "step": 740
    },
    {
      "epoch": 0.1967892283790782,
      "grad_norm": 0.5103040933609009,
      "learning_rate": 4.675470395304678e-05,
      "loss": 0.2111,
      "step": 760
    },
    {
      "epoch": 0.20196789228379078,
      "grad_norm": 1.0113095045089722,
      "learning_rate": 4.666839288796824e-05,
      "loss": 0.303,
      "step": 780
    },
    {
      "epoch": 0.20714655618850336,
      "grad_norm": 0.47185009717941284,
      "learning_rate": 4.658208182288969e-05,
      "loss": 0.2677,
      "step": 800
    },
    {
      "epoch": 0.21232522009321594,
      "grad_norm": 0.42445534467697144,
      "learning_rate": 4.649577075781115e-05,
      "loss": 0.323,
      "step": 820
    },
    {
      "epoch": 0.21750388399792853,
      "grad_norm": 1.3312263488769531,
      "learning_rate": 4.640945969273261e-05,
      "loss": 0.4778,
      "step": 840
    },
    {
      "epoch": 0.2226825479026411,
      "grad_norm": 0.7030391693115234,
      "learning_rate": 4.6323148627654065e-05,
      "loss": 0.3839,
      "step": 860
    },
    {
      "epoch": 0.2278612118073537,
      "grad_norm": 2.323596477508545,
      "learning_rate": 4.6236837562575525e-05,
      "loss": 0.3577,
      "step": 880
    },
    {
      "epoch": 0.23303987571206627,
      "grad_norm": 0.8864248991012573,
      "learning_rate": 4.6150526497496984e-05,
      "loss": 0.2524,
      "step": 900
    },
    {
      "epoch": 0.23821853961677888,
      "grad_norm": 0.2448681741952896,
      "learning_rate": 4.606421543241844e-05,
      "loss": 0.3743,
      "step": 920
    },
    {
      "epoch": 0.24339720352149147,
      "grad_norm": 0.18137586116790771,
      "learning_rate": 4.59779043673399e-05,
      "loss": 0.2704,
      "step": 940
    },
    {
      "epoch": 0.24857586742620405,
      "grad_norm": 0.22925706207752228,
      "learning_rate": 4.5891593302261356e-05,
      "loss": 0.4621,
      "step": 960
    },
    {
      "epoch": 0.25375453133091663,
      "grad_norm": 0.3992922008037567,
      "learning_rate": 4.580528223718281e-05,
      "loss": 0.4541,
      "step": 980
    },
    {
      "epoch": 0.2589331952356292,
      "grad_norm": 0.5338646769523621,
      "learning_rate": 4.571897117210426e-05,
      "loss": 0.1951,
      "step": 1000
    },
    {
      "epoch": 0.2641118591403418,
      "grad_norm": 0.16165930032730103,
      "learning_rate": 4.563266010702572e-05,
      "loss": 0.258,
      "step": 1020
    },
    {
      "epoch": 0.26929052304505435,
      "grad_norm": 0.4149869978427887,
      "learning_rate": 4.554634904194718e-05,
      "loss": 0.3759,
      "step": 1040
    },
    {
      "epoch": 0.27446918694976696,
      "grad_norm": 0.2524016201496124,
      "learning_rate": 4.5460037976868634e-05,
      "loss": 0.3403,
      "step": 1060
    },
    {
      "epoch": 0.2796478508544795,
      "grad_norm": 0.2906433641910553,
      "learning_rate": 4.537372691179009e-05,
      "loss": 0.2319,
      "step": 1080
    },
    {
      "epoch": 0.28482651475919213,
      "grad_norm": 1.2414487600326538,
      "learning_rate": 4.528741584671155e-05,
      "loss": 0.4094,
      "step": 1100
    },
    {
      "epoch": 0.29000517866390474,
      "grad_norm": 0.7795910239219666,
      "learning_rate": 4.5201104781633006e-05,
      "loss": 0.405,
      "step": 1120
    },
    {
      "epoch": 0.2951838425686173,
      "grad_norm": 0.6523194909095764,
      "learning_rate": 4.5114793716554465e-05,
      "loss": 0.2004,
      "step": 1140
    },
    {
      "epoch": 0.3003625064733299,
      "grad_norm": 0.38404878973960876,
      "learning_rate": 4.5028482651475925e-05,
      "loss": 0.2744,
      "step": 1160
    },
    {
      "epoch": 0.30554117037804246,
      "grad_norm": 0.21534408628940582,
      "learning_rate": 4.494217158639738e-05,
      "loss": 0.2707,
      "step": 1180
    },
    {
      "epoch": 0.31071983428275507,
      "grad_norm": 0.6847185492515564,
      "learning_rate": 4.485586052131884e-05,
      "loss": 0.199,
      "step": 1200
    },
    {
      "epoch": 0.3158984981874676,
      "grad_norm": 0.2447708696126938,
      "learning_rate": 4.476954945624029e-05,
      "loss": 0.4025,
      "step": 1220
    },
    {
      "epoch": 0.32107716209218023,
      "grad_norm": 2.386948347091675,
      "learning_rate": 4.468323839116175e-05,
      "loss": 0.2208,
      "step": 1240
    },
    {
      "epoch": 0.3262558259968928,
      "grad_norm": 0.6413496732711792,
      "learning_rate": 4.45969273260832e-05,
      "loss": 0.2532,
      "step": 1260
    },
    {
      "epoch": 0.3314344899016054,
      "grad_norm": 0.30791041254997253,
      "learning_rate": 4.451061626100466e-05,
      "loss": 0.2754,
      "step": 1280
    },
    {
      "epoch": 0.33661315380631796,
      "grad_norm": 0.5559980869293213,
      "learning_rate": 4.442430519592612e-05,
      "loss": 0.2665,
      "step": 1300
    },
    {
      "epoch": 0.34179181771103057,
      "grad_norm": 0.5964084267616272,
      "learning_rate": 4.4337994130847574e-05,
      "loss": 0.2523,
      "step": 1320
    },
    {
      "epoch": 0.3469704816157431,
      "grad_norm": 2.96209979057312,
      "learning_rate": 4.4251683065769034e-05,
      "loss": 0.3144,
      "step": 1340
    },
    {
      "epoch": 0.35214914552045573,
      "grad_norm": 0.36832597851753235,
      "learning_rate": 4.4165372000690494e-05,
      "loss": 0.3956,
      "step": 1360
    },
    {
      "epoch": 0.3573278094251683,
      "grad_norm": 4.451231002807617,
      "learning_rate": 4.4079060935611946e-05,
      "loss": 0.3544,
      "step": 1380
    },
    {
      "epoch": 0.3625064733298809,
      "grad_norm": 0.40332522988319397,
      "learning_rate": 4.3992749870533406e-05,
      "loss": 0.2304,
      "step": 1400
    },
    {
      "epoch": 0.36768513723459345,
      "grad_norm": 0.2975614368915558,
      "learning_rate": 4.3906438805454866e-05,
      "loss": 0.1815,
      "step": 1420
    },
    {
      "epoch": 0.37286380113930606,
      "grad_norm": 0.30432796478271484,
      "learning_rate": 4.382012774037632e-05,
      "loss": 0.4212,
      "step": 1440
    },
    {
      "epoch": 0.3780424650440186,
      "grad_norm": 0.40922942757606506,
      "learning_rate": 4.373381667529777e-05,
      "loss": 0.4094,
      "step": 1460
    },
    {
      "epoch": 0.3832211289487312,
      "grad_norm": 0.22560366988182068,
      "learning_rate": 4.364750561021923e-05,
      "loss": 0.3407,
      "step": 1480
    },
    {
      "epoch": 0.38839979285344384,
      "grad_norm": 0.5387113690376282,
      "learning_rate": 4.356119454514069e-05,
      "loss": 0.4131,
      "step": 1500
    },
    {
      "epoch": 0.3935784567581564,
      "grad_norm": 0.5973080396652222,
      "learning_rate": 4.347488348006214e-05,
      "loss": 0.3049,
      "step": 1520
    },
    {
      "epoch": 0.398757120662869,
      "grad_norm": 0.36984360218048096,
      "learning_rate": 4.33885724149836e-05,
      "loss": 0.4282,
      "step": 1540
    },
    {
      "epoch": 0.40393578456758156,
      "grad_norm": 0.43832510709762573,
      "learning_rate": 4.330226134990506e-05,
      "loss": 0.3696,
      "step": 1560
    },
    {
      "epoch": 0.40911444847229417,
      "grad_norm": 0.2445806860923767,
      "learning_rate": 4.3215950284826515e-05,
      "loss": 0.5044,
      "step": 1580
    },
    {
      "epoch": 0.4142931123770067,
      "grad_norm": 0.3528139591217041,
      "learning_rate": 4.3129639219747975e-05,
      "loss": 0.3842,
      "step": 1600
    },
    {
      "epoch": 0.41947177628171933,
      "grad_norm": 0.23381169140338898,
      "learning_rate": 4.3043328154669434e-05,
      "loss": 0.2601,
      "step": 1620
    },
    {
      "epoch": 0.4246504401864319,
      "grad_norm": 0.34920090436935425,
      "learning_rate": 4.295701708959089e-05,
      "loss": 0.4185,
      "step": 1640
    },
    {
      "epoch": 0.4298291040911445,
      "grad_norm": 0.3530692756175995,
      "learning_rate": 4.2870706024512347e-05,
      "loss": 0.3769,
      "step": 1660
    },
    {
      "epoch": 0.43500776799585705,
      "grad_norm": 0.221157968044281,
      "learning_rate": 4.27843949594338e-05,
      "loss": 0.1591,
      "step": 1680
    },
    {
      "epoch": 0.44018643190056966,
      "grad_norm": 0.4736630320549011,
      "learning_rate": 4.269808389435526e-05,
      "loss": 0.2705,
      "step": 1700
    },
    {
      "epoch": 0.4453650958052822,
      "grad_norm": 0.23429280519485474,
      "learning_rate": 4.261177282927671e-05,
      "loss": 0.3141,
      "step": 1720
    },
    {
      "epoch": 0.45054375970999483,
      "grad_norm": 0.4009598195552826,
      "learning_rate": 4.252546176419817e-05,
      "loss": 0.3532,
      "step": 1740
    },
    {
      "epoch": 0.4557224236147074,
      "grad_norm": 0.5748755931854248,
      "learning_rate": 4.243915069911963e-05,
      "loss": 0.2976,
      "step": 1760
    },
    {
      "epoch": 0.46090108751942,
      "grad_norm": 0.9929515719413757,
      "learning_rate": 4.2352839634041084e-05,
      "loss": 0.207,
      "step": 1780
    },
    {
      "epoch": 0.46607975142413255,
      "grad_norm": 0.613699734210968,
      "learning_rate": 4.226652856896254e-05,
      "loss": 0.322,
      "step": 1800
    },
    {
      "epoch": 0.47125841532884516,
      "grad_norm": 0.4945605397224426,
      "learning_rate": 4.2180217503884e-05,
      "loss": 0.3985,
      "step": 1820
    },
    {
      "epoch": 0.47643707923355777,
      "grad_norm": 0.2929111123085022,
      "learning_rate": 4.2093906438805456e-05,
      "loss": 0.3098,
      "step": 1840
    },
    {
      "epoch": 0.4816157431382703,
      "grad_norm": 0.23231986165046692,
      "learning_rate": 4.2007595373726915e-05,
      "loss": 0.3984,
      "step": 1860
    },
    {
      "epoch": 0.48679440704298294,
      "grad_norm": 0.2671286165714264,
      "learning_rate": 4.1921284308648375e-05,
      "loss": 0.3078,
      "step": 1880
    },
    {
      "epoch": 0.4919730709476955,
      "grad_norm": 0.7535843849182129,
      "learning_rate": 4.183497324356983e-05,
      "loss": 0.202,
      "step": 1900
    },
    {
      "epoch": 0.4971517348524081,
      "grad_norm": 0.6174108386039734,
      "learning_rate": 4.174866217849128e-05,
      "loss": 0.4872,
      "step": 1920
    },
    {
      "epoch": 0.5023303987571207,
      "grad_norm": 0.7214367985725403,
      "learning_rate": 4.166235111341274e-05,
      "loss": 0.2632,
      "step": 1940
    },
    {
      "epoch": 0.5075090626618333,
      "grad_norm": 0.43288886547088623,
      "learning_rate": 4.15760400483342e-05,
      "loss": 0.254,
      "step": 1960
    },
    {
      "epoch": 0.5126877265665458,
      "grad_norm": 0.23964056372642517,
      "learning_rate": 4.148972898325565e-05,
      "loss": 0.257,
      "step": 1980
    },
    {
      "epoch": 0.5178663904712584,
      "grad_norm": 0.2910713851451874,
      "learning_rate": 4.140341791817711e-05,
      "loss": 0.4849,
      "step": 2000
    },
    {
      "epoch": 0.523045054375971,
      "grad_norm": 0.3571830689907074,
      "learning_rate": 4.131710685309857e-05,
      "loss": 0.4354,
      "step": 2020
    },
    {
      "epoch": 0.5282237182806836,
      "grad_norm": 0.17866720259189606,
      "learning_rate": 4.1230795788020024e-05,
      "loss": 0.2375,
      "step": 2040
    },
    {
      "epoch": 0.5334023821853962,
      "grad_norm": 0.28448501229286194,
      "learning_rate": 4.1144484722941484e-05,
      "loss": 0.3183,
      "step": 2060
    },
    {
      "epoch": 0.5385810460901087,
      "grad_norm": 0.3942638039588928,
      "learning_rate": 4.1058173657862943e-05,
      "loss": 0.418,
      "step": 2080
    },
    {
      "epoch": 0.5437597099948214,
      "grad_norm": 0.7856264710426331,
      "learning_rate": 4.0971862592784396e-05,
      "loss": 0.2423,
      "step": 2100
    },
    {
      "epoch": 0.5489383738995339,
      "grad_norm": 0.6947046518325806,
      "learning_rate": 4.0885551527705856e-05,
      "loss": 0.3978,
      "step": 2120
    },
    {
      "epoch": 0.5541170378042465,
      "grad_norm": 0.3705627918243408,
      "learning_rate": 4.079924046262731e-05,
      "loss": 0.3006,
      "step": 2140
    },
    {
      "epoch": 0.559295701708959,
      "grad_norm": 0.6691087484359741,
      "learning_rate": 4.071292939754877e-05,
      "loss": 0.4198,
      "step": 2160
    },
    {
      "epoch": 0.5644743656136717,
      "grad_norm": 0.5391852855682373,
      "learning_rate": 4.062661833247022e-05,
      "loss": 0.2998,
      "step": 2180
    },
    {
      "epoch": 0.5696530295183843,
      "grad_norm": 0.7486177682876587,
      "learning_rate": 4.054030726739168e-05,
      "loss": 0.2204,
      "step": 2200
    },
    {
      "epoch": 0.5748316934230968,
      "grad_norm": 0.1917324811220169,
      "learning_rate": 4.045399620231314e-05,
      "loss": 0.2013,
      "step": 2220
    },
    {
      "epoch": 0.5800103573278095,
      "grad_norm": 0.3394862711429596,
      "learning_rate": 4.036768513723459e-05,
      "loss": 0.2894,
      "step": 2240
    },
    {
      "epoch": 0.585189021232522,
      "grad_norm": 0.287281334400177,
      "learning_rate": 4.028137407215605e-05,
      "loss": 0.4047,
      "step": 2260
    },
    {
      "epoch": 0.5903676851372346,
      "grad_norm": 0.4311116337776184,
      "learning_rate": 4.019506300707751e-05,
      "loss": 0.2799,
      "step": 2280
    },
    {
      "epoch": 0.5955463490419471,
      "grad_norm": 1.2925471067428589,
      "learning_rate": 4.0108751941998965e-05,
      "loss": 0.2655,
      "step": 2300
    },
    {
      "epoch": 0.6007250129466598,
      "grad_norm": 0.1832837015390396,
      "learning_rate": 4.0022440876920424e-05,
      "loss": 0.4018,
      "step": 2320
    },
    {
      "epoch": 0.6059036768513724,
      "grad_norm": 0.3604970872402191,
      "learning_rate": 3.9936129811841884e-05,
      "loss": 0.5057,
      "step": 2340
    },
    {
      "epoch": 0.6110823407560849,
      "grad_norm": 0.28133347630500793,
      "learning_rate": 3.984981874676334e-05,
      "loss": 0.2671,
      "step": 2360
    },
    {
      "epoch": 0.6162610046607975,
      "grad_norm": 0.6586342453956604,
      "learning_rate": 3.976350768168479e-05,
      "loss": 0.5012,
      "step": 2380
    },
    {
      "epoch": 0.6214396685655101,
      "grad_norm": 0.49067237973213196,
      "learning_rate": 3.967719661660625e-05,
      "loss": 0.2996,
      "step": 2400
    },
    {
      "epoch": 0.6266183324702227,
      "grad_norm": 0.4012816250324249,
      "learning_rate": 3.959088555152771e-05,
      "loss": 0.2418,
      "step": 2420
    },
    {
      "epoch": 0.6317969963749352,
      "grad_norm": 0.27531805634498596,
      "learning_rate": 3.950457448644916e-05,
      "loss": 0.2332,
      "step": 2440
    },
    {
      "epoch": 0.6369756602796478,
      "grad_norm": 1.5769098997116089,
      "learning_rate": 3.941826342137062e-05,
      "loss": 0.433,
      "step": 2460
    },
    {
      "epoch": 0.6421543241843605,
      "grad_norm": 0.4245220422744751,
      "learning_rate": 3.933195235629208e-05,
      "loss": 0.2843,
      "step": 2480
    },
    {
      "epoch": 0.647332988089073,
      "grad_norm": 0.24415987730026245,
      "learning_rate": 3.9245641291213534e-05,
      "loss": 0.2708,
      "step": 2500
    },
    {
      "epoch": 0.6525116519937856,
      "grad_norm": 0.17765936255455017,
      "learning_rate": 3.915933022613499e-05,
      "loss": 0.2521,
      "step": 2520
    },
    {
      "epoch": 0.6576903158984981,
      "grad_norm": 1.2618598937988281,
      "learning_rate": 3.907301916105645e-05,
      "loss": 0.296,
      "step": 2540
    },
    {
      "epoch": 0.6628689798032108,
      "grad_norm": 0.32594192028045654,
      "learning_rate": 3.8986708095977905e-05,
      "loss": 0.1783,
      "step": 2560
    },
    {
      "epoch": 0.6680476437079234,
      "grad_norm": 0.8046995997428894,
      "learning_rate": 3.8900397030899365e-05,
      "loss": 0.3756,
      "step": 2580
    },
    {
      "epoch": 0.6732263076126359,
      "grad_norm": 0.48054957389831543,
      "learning_rate": 3.881408596582082e-05,
      "loss": 0.2136,
      "step": 2600
    },
    {
      "epoch": 0.6784049715173486,
      "grad_norm": 0.5415575504302979,
      "learning_rate": 3.872777490074228e-05,
      "loss": 0.3006,
      "step": 2620
    },
    {
      "epoch": 0.6835836354220611,
      "grad_norm": 2.0498526096343994,
      "learning_rate": 3.864146383566373e-05,
      "loss": 0.2425,
      "step": 2640
    },
    {
      "epoch": 0.6887622993267737,
      "grad_norm": 0.2906571328639984,
      "learning_rate": 3.855515277058519e-05,
      "loss": 0.1982,
      "step": 2660
    },
    {
      "epoch": 0.6939409632314862,
      "grad_norm": 0.3364759683609009,
      "learning_rate": 3.846884170550665e-05,
      "loss": 0.2315,
      "step": 2680
    },
    {
      "epoch": 0.6991196271361989,
      "grad_norm": 0.2905983328819275,
      "learning_rate": 3.83825306404281e-05,
      "loss": 0.1992,
      "step": 2700
    },
    {
      "epoch": 0.7042982910409115,
      "grad_norm": 1.0067291259765625,
      "learning_rate": 3.829621957534956e-05,
      "loss": 0.2553,
      "step": 2720
    },
    {
      "epoch": 0.709476954945624,
      "grad_norm": 0.2728920578956604,
      "learning_rate": 3.820990851027102e-05,
      "loss": 0.3135,
      "step": 2740
    },
    {
      "epoch": 0.7146556188503366,
      "grad_norm": 0.9197738170623779,
      "learning_rate": 3.8123597445192474e-05,
      "loss": 0.2683,
      "step": 2760
    },
    {
      "epoch": 0.7198342827550492,
      "grad_norm": 0.5005480647087097,
      "learning_rate": 3.8037286380113934e-05,
      "loss": 0.2514,
      "step": 2780
    },
    {
      "epoch": 0.7250129466597618,
      "grad_norm": 0.6712875366210938,
      "learning_rate": 3.795097531503539e-05,
      "loss": 0.2957,
      "step": 2800
    },
    {
      "epoch": 0.7301916105644743,
      "grad_norm": 0.2787967324256897,
      "learning_rate": 3.7864664249956846e-05,
      "loss": 0.3263,
      "step": 2820
    },
    {
      "epoch": 0.7353702744691869,
      "grad_norm": 0.601595938205719,
      "learning_rate": 3.77783531848783e-05,
      "loss": 0.2674,
      "step": 2840
    },
    {
      "epoch": 0.7405489383738996,
      "grad_norm": 0.7207546234130859,
      "learning_rate": 3.769204211979976e-05,
      "loss": 0.3049,
      "step": 2860
    },
    {
      "epoch": 0.7457276022786121,
      "grad_norm": 0.1487516462802887,
      "learning_rate": 3.760573105472122e-05,
      "loss": 0.2199,
      "step": 2880
    },
    {
      "epoch": 0.7509062661833247,
      "grad_norm": 0.19878032803535461,
      "learning_rate": 3.751941998964267e-05,
      "loss": 0.1885,
      "step": 2900
    },
    {
      "epoch": 0.7560849300880372,
      "grad_norm": 0.18069666624069214,
      "learning_rate": 3.743310892456413e-05,
      "loss": 0.3924,
      "step": 2920
    },
    {
      "epoch": 0.7612635939927499,
      "grad_norm": 0.2777796685695648,
      "learning_rate": 3.734679785948559e-05,
      "loss": 0.2324,
      "step": 2940
    },
    {
      "epoch": 0.7664422578974625,
      "grad_norm": 0.49304449558258057,
      "learning_rate": 3.726048679440704e-05,
      "loss": 0.3915,
      "step": 2960
    },
    {
      "epoch": 0.771620921802175,
      "grad_norm": 0.1731625348329544,
      "learning_rate": 3.71741757293285e-05,
      "loss": 0.1408,
      "step": 2980
    },
    {
      "epoch": 0.7767995857068877,
      "grad_norm": 0.37605467438697815,
      "learning_rate": 3.708786466424996e-05,
      "loss": 0.2196,
      "step": 3000
    },
    {
      "epoch": 0.7819782496116002,
      "grad_norm": 0.26363804936408997,
      "learning_rate": 3.7001553599171415e-05,
      "loss": 0.2876,
      "step": 3020
    },
    {
      "epoch": 0.7871569135163128,
      "grad_norm": 0.5399924516677856,
      "learning_rate": 3.691524253409287e-05,
      "loss": 0.2097,
      "step": 3040
    },
    {
      "epoch": 0.7923355774210253,
      "grad_norm": 0.750304639339447,
      "learning_rate": 3.682893146901433e-05,
      "loss": 0.3571,
      "step": 3060
    },
    {
      "epoch": 0.797514241325738,
      "grad_norm": 0.3860228657722473,
      "learning_rate": 3.674262040393579e-05,
      "loss": 0.3671,
      "step": 3080
    },
    {
      "epoch": 0.8026929052304506,
      "grad_norm": 0.382425457239151,
      "learning_rate": 3.665630933885724e-05,
      "loss": 0.2678,
      "step": 3100
    },
    {
      "epoch": 0.8078715691351631,
      "grad_norm": 90.97516632080078,
      "learning_rate": 3.65699982737787e-05,
      "loss": 0.2089,
      "step": 3120
    },
    {
      "epoch": 0.8130502330398757,
      "grad_norm": 0.753862738609314,
      "learning_rate": 3.648368720870016e-05,
      "loss": 0.3125,
      "step": 3140
    },
    {
      "epoch": 0.8182288969445883,
      "grad_norm": 0.4268838167190552,
      "learning_rate": 3.639737614362161e-05,
      "loss": 0.1657,
      "step": 3160
    },
    {
      "epoch": 0.8234075608493009,
      "grad_norm": 0.3272823393344879,
      "learning_rate": 3.631106507854307e-05,
      "loss": 0.3648,
      "step": 3180
    },
    {
      "epoch": 0.8285862247540134,
      "grad_norm": 0.15284357964992523,
      "learning_rate": 3.622475401346453e-05,
      "loss": 0.2082,
      "step": 3200
    },
    {
      "epoch": 0.833764888658726,
      "grad_norm": 0.14540927112102509,
      "learning_rate": 3.6138442948385983e-05,
      "loss": 0.2249,
      "step": 3220
    },
    {
      "epoch": 0.8389435525634387,
      "grad_norm": 0.28681761026382446,
      "learning_rate": 3.605213188330744e-05,
      "loss": 0.3839,
      "step": 3240
    },
    {
      "epoch": 0.8441222164681512,
      "grad_norm": 0.23126360774040222,
      "learning_rate": 3.59658208182289e-05,
      "loss": 0.3072,
      "step": 3260
    },
    {
      "epoch": 0.8493008803728638,
      "grad_norm": 0.16833344101905823,
      "learning_rate": 3.5879509753150355e-05,
      "loss": 0.5178,
      "step": 3280
    },
    {
      "epoch": 0.8544795442775763,
      "grad_norm": 0.5017094612121582,
      "learning_rate": 3.579319868807181e-05,
      "loss": 0.2528,
      "step": 3300
    },
    {
      "epoch": 0.859658208182289,
      "grad_norm": 0.6041623950004578,
      "learning_rate": 3.570688762299327e-05,
      "loss": 0.3182,
      "step": 3320
    },
    {
      "epoch": 0.8648368720870016,
      "grad_norm": 0.37381231784820557,
      "learning_rate": 3.562057655791473e-05,
      "loss": 0.304,
      "step": 3340
    },
    {
      "epoch": 0.8700155359917141,
      "grad_norm": 0.47815319895744324,
      "learning_rate": 3.553426549283618e-05,
      "loss": 0.2498,
      "step": 3360
    },
    {
      "epoch": 0.8751941998964268,
      "grad_norm": 0.6863347291946411,
      "learning_rate": 3.544795442775764e-05,
      "loss": 0.2666,
      "step": 3380
    },
    {
      "epoch": 0.8803728638011393,
      "grad_norm": 0.38463932275772095,
      "learning_rate": 3.53616433626791e-05,
      "loss": 0.2579,
      "step": 3400
    },
    {
      "epoch": 0.8855515277058519,
      "grad_norm": 0.49278998374938965,
      "learning_rate": 3.527533229760055e-05,
      "loss": 0.2437,
      "step": 3420
    },
    {
      "epoch": 0.8907301916105644,
      "grad_norm": 0.2010909467935562,
      "learning_rate": 3.518902123252201e-05,
      "loss": 0.3184,
      "step": 3440
    },
    {
      "epoch": 0.8959088555152771,
      "grad_norm": 0.4222787022590637,
      "learning_rate": 3.510271016744347e-05,
      "loss": 0.2037,
      "step": 3460
    },
    {
      "epoch": 0.9010875194199897,
      "grad_norm": 0.9825772047042847,
      "learning_rate": 3.5016399102364924e-05,
      "loss": 0.2155,
      "step": 3480
    },
    {
      "epoch": 0.9062661833247022,
      "grad_norm": 0.6194919943809509,
      "learning_rate": 3.493008803728638e-05,
      "loss": 0.2684,
      "step": 3500
    },
    {
      "epoch": 0.9114448472294148,
      "grad_norm": 0.5779101252555847,
      "learning_rate": 3.4843776972207836e-05,
      "loss": 0.2513,
      "step": 3520
    },
    {
      "epoch": 0.9166235111341274,
      "grad_norm": 0.19147661328315735,
      "learning_rate": 3.4757465907129296e-05,
      "loss": 0.1901,
      "step": 3540
    },
    {
      "epoch": 0.92180217503884,
      "grad_norm": 0.18686838448047638,
      "learning_rate": 3.467115484205075e-05,
      "loss": 0.3113,
      "step": 3560
    },
    {
      "epoch": 0.9269808389435525,
      "grad_norm": 0.3124150335788727,
      "learning_rate": 3.458484377697221e-05,
      "loss": 0.2878,
      "step": 3580
    },
    {
      "epoch": 0.9321595028482651,
      "grad_norm": 1.5176973342895508,
      "learning_rate": 3.449853271189367e-05,
      "loss": 0.2897,
      "step": 3600
    },
    {
      "epoch": 0.9373381667529778,
      "grad_norm": 0.25537213683128357,
      "learning_rate": 3.441222164681512e-05,
      "loss": 0.3078,
      "step": 3620
    },
    {
      "epoch": 0.9425168306576903,
      "grad_norm": 1.023582935333252,
      "learning_rate": 3.432591058173658e-05,
      "loss": 0.3669,
      "step": 3640
    },
    {
      "epoch": 0.9476954945624029,
      "grad_norm": 2.9341962337493896,
      "learning_rate": 3.423959951665804e-05,
      "loss": 0.2058,
      "step": 3660
    },
    {
      "epoch": 0.9528741584671155,
      "grad_norm": 0.5623692870140076,
      "learning_rate": 3.415328845157949e-05,
      "loss": 0.3388,
      "step": 3680
    },
    {
      "epoch": 0.9580528223718281,
      "grad_norm": 0.7481259107589722,
      "learning_rate": 3.406697738650095e-05,
      "loss": 0.2374,
      "step": 3700
    },
    {
      "epoch": 0.9632314862765406,
      "grad_norm": 0.41873887181282043,
      "learning_rate": 3.3980666321422405e-05,
      "loss": 0.2154,
      "step": 3720
    },
    {
      "epoch": 0.9684101501812532,
      "grad_norm": 0.2509080469608307,
      "learning_rate": 3.3894355256343865e-05,
      "loss": 0.2517,
      "step": 3740
    },
    {
      "epoch": 0.9735888140859659,
      "grad_norm": 0.14607271552085876,
      "learning_rate": 3.380804419126532e-05,
      "loss": 0.3121,
      "step": 3760
    },
    {
      "epoch": 0.9787674779906784,
      "grad_norm": 0.6303099393844604,
      "learning_rate": 3.372173312618678e-05,
      "loss": 0.2354,
      "step": 3780
    },
    {
      "epoch": 0.983946141895391,
      "grad_norm": 0.23458294570446014,
      "learning_rate": 3.3635422061108237e-05,
      "loss": 0.4003,
      "step": 3800
    },
    {
      "epoch": 0.9891248058001035,
      "grad_norm": 0.22983191907405853,
      "learning_rate": 3.354911099602969e-05,
      "loss": 0.374,
      "step": 3820
    },
    {
      "epoch": 0.9943034697048162,
      "grad_norm": 0.2524656355381012,
      "learning_rate": 3.346279993095115e-05,
      "loss": 0.1468,
      "step": 3840
    },
    {
      "epoch": 0.9994821336095288,
      "grad_norm": 0.884723961353302,
      "learning_rate": 3.337648886587261e-05,
      "loss": 0.3482,
      "step": 3860
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.254821240901947,
      "eval_runtime": 31.2697,
      "eval_samples_per_second": 27.471,
      "eval_steps_per_second": 3.454,
      "step": 3862
    },
    {
      "epoch": 1.0046607975142414,
      "grad_norm": 0.4414854943752289,
      "learning_rate": 3.329017780079406e-05,
      "loss": 0.2429,
      "step": 3880
    },
    {
      "epoch": 1.0098394614189539,
      "grad_norm": 0.5112912058830261,
      "learning_rate": 3.320386673571552e-05,
      "loss": 0.2165,
      "step": 3900
    },
    {
      "epoch": 1.0150181253236665,
      "grad_norm": 0.5789859294891357,
      "learning_rate": 3.311755567063698e-05,
      "loss": 0.1981,
      "step": 3920
    },
    {
      "epoch": 1.020196789228379,
      "grad_norm": 0.28978484869003296,
      "learning_rate": 3.303124460555844e-05,
      "loss": 0.2626,
      "step": 3940
    },
    {
      "epoch": 1.0253754531330916,
      "grad_norm": 0.23465384542942047,
      "learning_rate": 3.2944933540479886e-05,
      "loss": 0.1815,
      "step": 3960
    },
    {
      "epoch": 1.0305541170378043,
      "grad_norm": 0.20004992187023163,
      "learning_rate": 3.2858622475401346e-05,
      "loss": 0.4162,
      "step": 3980
    },
    {
      "epoch": 1.0357327809425168,
      "grad_norm": 0.30575883388519287,
      "learning_rate": 3.2772311410322805e-05,
      "loss": 0.2588,
      "step": 4000
    },
    {
      "epoch": 1.0409114448472294,
      "grad_norm": 0.21477967500686646,
      "learning_rate": 3.268600034524426e-05,
      "loss": 0.2015,
      "step": 4020
    },
    {
      "epoch": 1.046090108751942,
      "grad_norm": 0.3944834768772125,
      "learning_rate": 3.259968928016572e-05,
      "loss": 0.2107,
      "step": 4040
    },
    {
      "epoch": 1.0512687726566545,
      "grad_norm": 0.3462982773780823,
      "learning_rate": 3.251337821508718e-05,
      "loss": 0.1998,
      "step": 4060
    },
    {
      "epoch": 1.0564474365613672,
      "grad_norm": 0.23455405235290527,
      "learning_rate": 3.242706715000863e-05,
      "loss": 0.2899,
      "step": 4080
    },
    {
      "epoch": 1.0616261004660799,
      "grad_norm": 0.2957875728607178,
      "learning_rate": 3.234075608493009e-05,
      "loss": 0.1858,
      "step": 4100
    },
    {
      "epoch": 1.0668047643707923,
      "grad_norm": 0.2957470715045929,
      "learning_rate": 3.225444501985155e-05,
      "loss": 0.2125,
      "step": 4120
    },
    {
      "epoch": 1.071983428275505,
      "grad_norm": 0.22679834067821503,
      "learning_rate": 3.216813395477301e-05,
      "loss": 0.2869,
      "step": 4140
    },
    {
      "epoch": 1.0771620921802174,
      "grad_norm": 0.5095988512039185,
      "learning_rate": 3.208182288969446e-05,
      "loss": 0.2066,
      "step": 4160
    },
    {
      "epoch": 1.08234075608493,
      "grad_norm": 2.4549975395202637,
      "learning_rate": 3.1995511824615914e-05,
      "loss": 0.2963,
      "step": 4180
    },
    {
      "epoch": 1.0875194199896427,
      "grad_norm": 0.23141801357269287,
      "learning_rate": 3.1909200759537374e-05,
      "loss": 0.3005,
      "step": 4200
    },
    {
      "epoch": 1.0926980838943552,
      "grad_norm": 0.2734453082084656,
      "learning_rate": 3.182288969445883e-05,
      "loss": 0.2149,
      "step": 4220
    },
    {
      "epoch": 1.0978767477990679,
      "grad_norm": 0.28460970520973206,
      "learning_rate": 3.1736578629380286e-05,
      "loss": 0.2114,
      "step": 4240
    },
    {
      "epoch": 1.1030554117037805,
      "grad_norm": 0.24111104011535645,
      "learning_rate": 3.1650267564301746e-05,
      "loss": 0.2924,
      "step": 4260
    },
    {
      "epoch": 1.108234075608493,
      "grad_norm": 0.7616519927978516,
      "learning_rate": 3.15639564992232e-05,
      "loss": 0.4716,
      "step": 4280
    },
    {
      "epoch": 1.1134127395132056,
      "grad_norm": 0.30913200974464417,
      "learning_rate": 3.147764543414466e-05,
      "loss": 0.3608,
      "step": 4300
    },
    {
      "epoch": 1.118591403417918,
      "grad_norm": 1.0456171035766602,
      "learning_rate": 3.139133436906612e-05,
      "loss": 0.351,
      "step": 4320
    },
    {
      "epoch": 1.1237700673226307,
      "grad_norm": 0.18778255581855774,
      "learning_rate": 3.130502330398758e-05,
      "loss": 0.4214,
      "step": 4340
    },
    {
      "epoch": 1.1289487312273434,
      "grad_norm": 0.9618195295333862,
      "learning_rate": 3.121871223890903e-05,
      "loss": 0.4149,
      "step": 4360
    },
    {
      "epoch": 1.1341273951320558,
      "grad_norm": 0.4410856068134308,
      "learning_rate": 3.113240117383049e-05,
      "loss": 0.2418,
      "step": 4380
    },
    {
      "epoch": 1.1393060590367685,
      "grad_norm": 0.4577919840812683,
      "learning_rate": 3.104609010875195e-05,
      "loss": 0.266,
      "step": 4400
    },
    {
      "epoch": 1.1444847229414812,
      "grad_norm": 1.6833752393722534,
      "learning_rate": 3.0959779043673395e-05,
      "loss": 0.2161,
      "step": 4420
    },
    {
      "epoch": 1.1496633868461936,
      "grad_norm": 0.25493377447128296,
      "learning_rate": 3.0873467978594855e-05,
      "loss": 0.2777,
      "step": 4440
    },
    {
      "epoch": 1.1548420507509063,
      "grad_norm": 0.431127667427063,
      "learning_rate": 3.0787156913516314e-05,
      "loss": 0.3357,
      "step": 4460
    },
    {
      "epoch": 1.160020714655619,
      "grad_norm": 0.273257315158844,
      "learning_rate": 3.070084584843777e-05,
      "loss": 0.3311,
      "step": 4480
    },
    {
      "epoch": 1.1651993785603314,
      "grad_norm": 0.3868120312690735,
      "learning_rate": 3.061453478335923e-05,
      "loss": 0.2086,
      "step": 4500
    },
    {
      "epoch": 1.170378042465044,
      "grad_norm": 1.823451280593872,
      "learning_rate": 3.0528223718280686e-05,
      "loss": 0.5632,
      "step": 4520
    },
    {
      "epoch": 1.1755567063697565,
      "grad_norm": 0.21200865507125854,
      "learning_rate": 3.0441912653202143e-05,
      "loss": 0.3816,
      "step": 4540
    },
    {
      "epoch": 1.1807353702744692,
      "grad_norm": 0.23389393091201782,
      "learning_rate": 3.03556015881236e-05,
      "loss": 0.3445,
      "step": 4560
    },
    {
      "epoch": 1.1859140341791818,
      "grad_norm": 0.17156128585338593,
      "learning_rate": 3.026929052304506e-05,
      "loss": 0.2509,
      "step": 4580
    },
    {
      "epoch": 1.1910926980838943,
      "grad_norm": 0.960458517074585,
      "learning_rate": 3.0182979457966515e-05,
      "loss": 0.2539,
      "step": 4600
    },
    {
      "epoch": 1.196271361988607,
      "grad_norm": 0.2681758403778076,
      "learning_rate": 3.009666839288797e-05,
      "loss": 0.1536,
      "step": 4620
    },
    {
      "epoch": 1.2014500258933196,
      "grad_norm": 0.3523464798927307,
      "learning_rate": 3.0010357327809424e-05,
      "loss": 0.3221,
      "step": 4640
    },
    {
      "epoch": 1.206628689798032,
      "grad_norm": 0.4022761285305023,
      "learning_rate": 2.9924046262730883e-05,
      "loss": 0.32,
      "step": 4660
    },
    {
      "epoch": 1.2118073537027447,
      "grad_norm": 0.56383216381073,
      "learning_rate": 2.983773519765234e-05,
      "loss": 0.3817,
      "step": 4680
    },
    {
      "epoch": 1.2169860176074572,
      "grad_norm": 0.1699005365371704,
      "learning_rate": 2.9751424132573796e-05,
      "loss": 0.2382,
      "step": 4700
    },
    {
      "epoch": 1.2221646815121698,
      "grad_norm": 0.17512567341327667,
      "learning_rate": 2.9665113067495255e-05,
      "loss": 0.3461,
      "step": 4720
    },
    {
      "epoch": 1.2273433454168825,
      "grad_norm": 0.32488813996315,
      "learning_rate": 2.957880200241671e-05,
      "loss": 0.2989,
      "step": 4740
    },
    {
      "epoch": 1.232522009321595,
      "grad_norm": 0.3490752577781677,
      "learning_rate": 2.9492490937338167e-05,
      "loss": 0.209,
      "step": 4760
    },
    {
      "epoch": 1.2377006732263076,
      "grad_norm": 0.5626912117004395,
      "learning_rate": 2.9406179872259627e-05,
      "loss": 0.3316,
      "step": 4780
    },
    {
      "epoch": 1.2428793371310203,
      "grad_norm": 0.7947790026664734,
      "learning_rate": 2.9319868807181083e-05,
      "loss": 0.2921,
      "step": 4800
    },
    {
      "epoch": 1.2480580010357327,
      "grad_norm": 0.5467687845230103,
      "learning_rate": 2.923355774210254e-05,
      "loss": 0.2688,
      "step": 4820
    },
    {
      "epoch": 1.2532366649404454,
      "grad_norm": 0.193255215883255,
      "learning_rate": 2.9147246677024e-05,
      "loss": 0.3029,
      "step": 4840
    },
    {
      "epoch": 1.258415328845158,
      "grad_norm": 0.8448724150657654,
      "learning_rate": 2.906093561194545e-05,
      "loss": 0.2874,
      "step": 4860
    },
    {
      "epoch": 1.2635939927498705,
      "grad_norm": 0.38589006662368774,
      "learning_rate": 2.8974624546866908e-05,
      "loss": 0.2203,
      "step": 4880
    },
    {
      "epoch": 1.2687726566545832,
      "grad_norm": 0.36077582836151123,
      "learning_rate": 2.8888313481788364e-05,
      "loss": 0.2257,
      "step": 4900
    },
    {
      "epoch": 1.2739513205592958,
      "grad_norm": 2.7415473461151123,
      "learning_rate": 2.8802002416709824e-05,
      "loss": 0.3491,
      "step": 4920
    },
    {
      "epoch": 1.2791299844640083,
      "grad_norm": 0.27782678604125977,
      "learning_rate": 2.871569135163128e-05,
      "loss": 0.203,
      "step": 4940
    },
    {
      "epoch": 1.284308648368721,
      "grad_norm": 0.14501982927322388,
      "learning_rate": 2.8629380286552736e-05,
      "loss": 0.4038,
      "step": 4960
    },
    {
      "epoch": 1.2894873122734334,
      "grad_norm": 0.3644997775554657,
      "learning_rate": 2.8543069221474196e-05,
      "loss": 0.2888,
      "step": 4980
    },
    {
      "epoch": 1.294665976178146,
      "grad_norm": 0.21384315192699432,
      "learning_rate": 2.8456758156395652e-05,
      "loss": 0.3746,
      "step": 5000
    },
    {
      "epoch": 1.2998446400828585,
      "grad_norm": 0.28254804015159607,
      "learning_rate": 2.8370447091317108e-05,
      "loss": 0.2465,
      "step": 5020
    },
    {
      "epoch": 1.3050233039875712,
      "grad_norm": 0.9299102425575256,
      "learning_rate": 2.8284136026238568e-05,
      "loss": 0.2557,
      "step": 5040
    },
    {
      "epoch": 1.3102019678922838,
      "grad_norm": 0.322980135679245,
      "learning_rate": 2.8197824961160024e-05,
      "loss": 0.2044,
      "step": 5060
    },
    {
      "epoch": 1.3153806317969963,
      "grad_norm": 0.49953675270080566,
      "learning_rate": 2.811151389608148e-05,
      "loss": 0.3529,
      "step": 5080
    },
    {
      "epoch": 1.320559295701709,
      "grad_norm": 0.17744676768779755,
      "learning_rate": 2.8025202831002933e-05,
      "loss": 0.3011,
      "step": 5100
    },
    {
      "epoch": 1.3257379596064216,
      "grad_norm": 0.3348313570022583,
      "learning_rate": 2.7938891765924392e-05,
      "loss": 0.1753,
      "step": 5120
    },
    {
      "epoch": 1.330916623511134,
      "grad_norm": 0.3342471420764923,
      "learning_rate": 2.785258070084585e-05,
      "loss": 0.1751,
      "step": 5140
    },
    {
      "epoch": 1.3360952874158467,
      "grad_norm": 0.3920888900756836,
      "learning_rate": 2.7766269635767305e-05,
      "loss": 0.2341,
      "step": 5160
    },
    {
      "epoch": 1.3412739513205594,
      "grad_norm": 0.2797766625881195,
      "learning_rate": 2.7679958570688764e-05,
      "loss": 0.1919,
      "step": 5180
    },
    {
      "epoch": 1.3464526152252718,
      "grad_norm": 0.3453388810157776,
      "learning_rate": 2.759364750561022e-05,
      "loss": 0.3087,
      "step": 5200
    },
    {
      "epoch": 1.3516312791299845,
      "grad_norm": 0.4211087226867676,
      "learning_rate": 2.7507336440531677e-05,
      "loss": 0.167,
      "step": 5220
    },
    {
      "epoch": 1.3568099430346972,
      "grad_norm": 0.5285706520080566,
      "learning_rate": 2.7421025375453136e-05,
      "loss": 0.1677,
      "step": 5240
    },
    {
      "epoch": 1.3619886069394096,
      "grad_norm": 0.35685718059539795,
      "learning_rate": 2.7334714310374593e-05,
      "loss": 0.2695,
      "step": 5260
    },
    {
      "epoch": 1.3671672708441223,
      "grad_norm": 10.442090034484863,
      "learning_rate": 2.724840324529605e-05,
      "loss": 0.2116,
      "step": 5280
    },
    {
      "epoch": 1.372345934748835,
      "grad_norm": 0.7130991220474243,
      "learning_rate": 2.7162092180217508e-05,
      "loss": 0.311,
      "step": 5300
    },
    {
      "epoch": 1.3775245986535474,
      "grad_norm": 0.2145075798034668,
      "learning_rate": 2.707578111513896e-05,
      "loss": 0.4922,
      "step": 5320
    },
    {
      "epoch": 1.38270326255826,
      "grad_norm": 1.1310871839523315,
      "learning_rate": 2.6989470050060417e-05,
      "loss": 0.3122,
      "step": 5340
    },
    {
      "epoch": 1.3878819264629725,
      "grad_norm": 0.2784018814563751,
      "learning_rate": 2.6903158984981873e-05,
      "loss": 0.2786,
      "step": 5360
    },
    {
      "epoch": 1.3930605903676851,
      "grad_norm": 0.10381808876991272,
      "learning_rate": 2.6816847919903333e-05,
      "loss": 0.2366,
      "step": 5380
    },
    {
      "epoch": 1.3982392542723976,
      "grad_norm": 0.31136274337768555,
      "learning_rate": 2.673053685482479e-05,
      "loss": 0.429,
      "step": 5400
    },
    {
      "epoch": 1.4034179181771103,
      "grad_norm": 0.27368438243865967,
      "learning_rate": 2.6644225789746245e-05,
      "loss": 0.3621,
      "step": 5420
    },
    {
      "epoch": 1.408596582081823,
      "grad_norm": 0.3555978238582611,
      "learning_rate": 2.6557914724667705e-05,
      "loss": 0.2832,
      "step": 5440
    },
    {
      "epoch": 1.4137752459865354,
      "grad_norm": 0.2738645076751709,
      "learning_rate": 2.647160365958916e-05,
      "loss": 0.2873,
      "step": 5460
    },
    {
      "epoch": 1.418953909891248,
      "grad_norm": 0.3688083291053772,
      "learning_rate": 2.6385292594510617e-05,
      "loss": 0.2567,
      "step": 5480
    },
    {
      "epoch": 1.4241325737959607,
      "grad_norm": 0.259634792804718,
      "learning_rate": 2.6298981529432077e-05,
      "loss": 0.3979,
      "step": 5500
    },
    {
      "epoch": 1.4293112377006731,
      "grad_norm": 0.521969199180603,
      "learning_rate": 2.6212670464353533e-05,
      "loss": 0.216,
      "step": 5520
    },
    {
      "epoch": 1.4344899016053858,
      "grad_norm": 0.21692129969596863,
      "learning_rate": 2.6126359399274986e-05,
      "loss": 0.3454,
      "step": 5540
    },
    {
      "epoch": 1.4396685655100985,
      "grad_norm": 2.4753360748291016,
      "learning_rate": 2.6040048334196442e-05,
      "loss": 0.3012,
      "step": 5560
    },
    {
      "epoch": 1.444847229414811,
      "grad_norm": 0.45407265424728394,
      "learning_rate": 2.59537372691179e-05,
      "loss": 0.3004,
      "step": 5580
    },
    {
      "epoch": 1.4500258933195236,
      "grad_norm": 0.4897046685218811,
      "learning_rate": 2.5867426204039358e-05,
      "loss": 0.2606,
      "step": 5600
    },
    {
      "epoch": 1.4552045572242363,
      "grad_norm": 0.5733627676963806,
      "learning_rate": 2.5781115138960814e-05,
      "loss": 0.5023,
      "step": 5620
    },
    {
      "epoch": 1.4603832211289487,
      "grad_norm": 0.4219778776168823,
      "learning_rate": 2.5694804073882274e-05,
      "loss": 0.4604,
      "step": 5640
    },
    {
      "epoch": 1.4655618850336614,
      "grad_norm": 0.28614431619644165,
      "learning_rate": 2.560849300880373e-05,
      "loss": 0.2555,
      "step": 5660
    },
    {
      "epoch": 1.470740548938374,
      "grad_norm": 0.35850805044174194,
      "learning_rate": 2.5522181943725186e-05,
      "loss": 0.3224,
      "step": 5680
    },
    {
      "epoch": 1.4759192128430865,
      "grad_norm": 0.4705115258693695,
      "learning_rate": 2.5435870878646646e-05,
      "loss": 0.3831,
      "step": 5700
    },
    {
      "epoch": 1.4810978767477991,
      "grad_norm": 0.18368317186832428,
      "learning_rate": 2.5349559813568102e-05,
      "loss": 0.1874,
      "step": 5720
    },
    {
      "epoch": 1.4862765406525116,
      "grad_norm": 0.22884337604045868,
      "learning_rate": 2.526324874848956e-05,
      "loss": 0.2714,
      "step": 5740
    },
    {
      "epoch": 1.4914552045572242,
      "grad_norm": 0.36233118176460266,
      "learning_rate": 2.5176937683411018e-05,
      "loss": 0.3115,
      "step": 5760
    },
    {
      "epoch": 1.4966338684619367,
      "grad_norm": 0.42438000440597534,
      "learning_rate": 2.509062661833247e-05,
      "loss": 0.3102,
      "step": 5780
    },
    {
      "epoch": 1.5018125323666494,
      "grad_norm": 0.2958745062351227,
      "learning_rate": 2.5004315553253927e-05,
      "loss": 0.1583,
      "step": 5800
    },
    {
      "epoch": 1.506991196271362,
      "grad_norm": 0.12163545191287994,
      "learning_rate": 2.4918004488175386e-05,
      "loss": 0.196,
      "step": 5820
    },
    {
      "epoch": 1.5121698601760745,
      "grad_norm": 0.26721176505088806,
      "learning_rate": 2.4831693423096842e-05,
      "loss": 0.2424,
      "step": 5840
    },
    {
      "epoch": 1.5173485240807871,
      "grad_norm": 0.5027908086776733,
      "learning_rate": 2.47453823580183e-05,
      "loss": 0.4201,
      "step": 5860
    },
    {
      "epoch": 1.5225271879854998,
      "grad_norm": 0.21376046538352966,
      "learning_rate": 2.4659071292939755e-05,
      "loss": 0.3206,
      "step": 5880
    },
    {
      "epoch": 1.5277058518902122,
      "grad_norm": 0.21611124277114868,
      "learning_rate": 2.4572760227861214e-05,
      "loss": 0.1911,
      "step": 5900
    },
    {
      "epoch": 1.532884515794925,
      "grad_norm": 0.2409532368183136,
      "learning_rate": 2.448644916278267e-05,
      "loss": 0.2254,
      "step": 5920
    },
    {
      "epoch": 1.5380631796996376,
      "grad_norm": 0.6284434795379639,
      "learning_rate": 2.4400138097704127e-05,
      "loss": 0.2149,
      "step": 5940
    },
    {
      "epoch": 1.54324184360435,
      "grad_norm": 0.33674904704093933,
      "learning_rate": 2.4313827032625583e-05,
      "loss": 0.2424,
      "step": 5960
    },
    {
      "epoch": 1.5484205075090627,
      "grad_norm": 0.4937274158000946,
      "learning_rate": 2.422751596754704e-05,
      "loss": 0.3574,
      "step": 5980
    },
    {
      "epoch": 1.5535991714137753,
      "grad_norm": 3.1451964378356934,
      "learning_rate": 2.41412049024685e-05,
      "loss": 0.3444,
      "step": 6000
    },
    {
      "epoch": 1.5587778353184878,
      "grad_norm": 1.4014679193496704,
      "learning_rate": 2.4054893837389955e-05,
      "loss": 0.2154,
      "step": 6020
    },
    {
      "epoch": 1.5639564992232005,
      "grad_norm": 0.21828630566596985,
      "learning_rate": 2.396858277231141e-05,
      "loss": 0.3624,
      "step": 6040
    },
    {
      "epoch": 1.5691351631279131,
      "grad_norm": 0.35876721143722534,
      "learning_rate": 2.3882271707232867e-05,
      "loss": 0.1925,
      "step": 6060
    },
    {
      "epoch": 1.5743138270326256,
      "grad_norm": 0.21988604962825775,
      "learning_rate": 2.3795960642154323e-05,
      "loss": 0.1501,
      "step": 6080
    },
    {
      "epoch": 1.579492490937338,
      "grad_norm": 0.30223068594932556,
      "learning_rate": 2.3709649577075783e-05,
      "loss": 0.1934,
      "step": 6100
    },
    {
      "epoch": 1.584671154842051,
      "grad_norm": 0.22461771965026855,
      "learning_rate": 2.362333851199724e-05,
      "loss": 0.4268,
      "step": 6120
    },
    {
      "epoch": 1.5898498187467633,
      "grad_norm": 0.42585667967796326,
      "learning_rate": 2.3537027446918695e-05,
      "loss": 0.2346,
      "step": 6140
    },
    {
      "epoch": 1.5950284826514758,
      "grad_norm": 0.5172669291496277,
      "learning_rate": 2.3450716381840155e-05,
      "loss": 0.2235,
      "step": 6160
    },
    {
      "epoch": 1.6002071465561885,
      "grad_norm": 0.8995460271835327,
      "learning_rate": 2.3364405316761608e-05,
      "loss": 0.1911,
      "step": 6180
    },
    {
      "epoch": 1.6053858104609011,
      "grad_norm": 0.546001672744751,
      "learning_rate": 2.3278094251683067e-05,
      "loss": 0.2758,
      "step": 6200
    },
    {
      "epoch": 1.6105644743656136,
      "grad_norm": 0.2765260338783264,
      "learning_rate": 2.3191783186604523e-05,
      "loss": 0.2515,
      "step": 6220
    },
    {
      "epoch": 1.6157431382703262,
      "grad_norm": 0.5400992035865784,
      "learning_rate": 2.310547212152598e-05,
      "loss": 0.2504,
      "step": 6240
    },
    {
      "epoch": 1.620921802175039,
      "grad_norm": 0.2836197316646576,
      "learning_rate": 2.301916105644744e-05,
      "loss": 0.2795,
      "step": 6260
    },
    {
      "epoch": 1.6261004660797513,
      "grad_norm": 0.2570933699607849,
      "learning_rate": 2.2932849991368892e-05,
      "loss": 0.1854,
      "step": 6280
    },
    {
      "epoch": 1.631279129984464,
      "grad_norm": 0.3516201972961426,
      "learning_rate": 2.284653892629035e-05,
      "loss": 0.3898,
      "step": 6300
    },
    {
      "epoch": 1.6364577938891767,
      "grad_norm": 0.3894850015640259,
      "learning_rate": 2.2760227861211808e-05,
      "loss": 0.2002,
      "step": 6320
    },
    {
      "epoch": 1.6416364577938891,
      "grad_norm": 0.8045259118080139,
      "learning_rate": 2.2673916796133264e-05,
      "loss": 0.3619,
      "step": 6340
    },
    {
      "epoch": 1.6468151216986018,
      "grad_norm": 0.1695263832807541,
      "learning_rate": 2.2587605731054724e-05,
      "loss": 0.379,
      "step": 6360
    },
    {
      "epoch": 1.6519937856033144,
      "grad_norm": 1.2479737997055054,
      "learning_rate": 2.250129466597618e-05,
      "loss": 0.2341,
      "step": 6380
    },
    {
      "epoch": 1.657172449508027,
      "grad_norm": 0.43997859954833984,
      "learning_rate": 2.2414983600897636e-05,
      "loss": 0.3724,
      "step": 6400
    },
    {
      "epoch": 1.6623511134127396,
      "grad_norm": 0.22006936371326447,
      "learning_rate": 2.2328672535819092e-05,
      "loss": 0.2113,
      "step": 6420
    },
    {
      "epoch": 1.6675297773174522,
      "grad_norm": 0.29723283648490906,
      "learning_rate": 2.2242361470740548e-05,
      "loss": 0.2297,
      "step": 6440
    },
    {
      "epoch": 1.6727084412221647,
      "grad_norm": 0.2580868899822235,
      "learning_rate": 2.2156050405662008e-05,
      "loss": 0.3049,
      "step": 6460
    },
    {
      "epoch": 1.677887105126877,
      "grad_norm": 0.46392664313316345,
      "learning_rate": 2.2069739340583464e-05,
      "loss": 0.2157,
      "step": 6480
    },
    {
      "epoch": 1.68306576903159,
      "grad_norm": 0.3438016176223755,
      "learning_rate": 2.1983428275504924e-05,
      "loss": 0.1979,
      "step": 6500
    },
    {
      "epoch": 1.6882444329363024,
      "grad_norm": 0.35134759545326233,
      "learning_rate": 2.1897117210426376e-05,
      "loss": 0.1711,
      "step": 6520
    },
    {
      "epoch": 1.6934230968410149,
      "grad_norm": 1.1649787425994873,
      "learning_rate": 2.1810806145347833e-05,
      "loss": 0.3139,
      "step": 6540
    },
    {
      "epoch": 1.6986017607457276,
      "grad_norm": 0.48185300827026367,
      "learning_rate": 2.1724495080269292e-05,
      "loss": 0.2108,
      "step": 6560
    },
    {
      "epoch": 1.7037804246504402,
      "grad_norm": 0.2178354412317276,
      "learning_rate": 2.163818401519075e-05,
      "loss": 0.2723,
      "step": 6580
    },
    {
      "epoch": 1.7089590885551527,
      "grad_norm": 0.3741907477378845,
      "learning_rate": 2.1551872950112208e-05,
      "loss": 0.1476,
      "step": 6600
    },
    {
      "epoch": 1.7141377524598653,
      "grad_norm": 0.4364340007305145,
      "learning_rate": 2.1465561885033664e-05,
      "loss": 0.3037,
      "step": 6620
    },
    {
      "epoch": 1.719316416364578,
      "grad_norm": 0.723739504814148,
      "learning_rate": 2.1379250819955117e-05,
      "loss": 0.3015,
      "step": 6640
    },
    {
      "epoch": 1.7244950802692904,
      "grad_norm": 0.17882616817951202,
      "learning_rate": 2.1292939754876576e-05,
      "loss": 0.2106,
      "step": 6660
    },
    {
      "epoch": 1.729673744174003,
      "grad_norm": 0.23835720121860504,
      "learning_rate": 2.1206628689798033e-05,
      "loss": 0.2381,
      "step": 6680
    },
    {
      "epoch": 1.7348524080787158,
      "grad_norm": 1.5524553060531616,
      "learning_rate": 2.1120317624719492e-05,
      "loss": 0.2598,
      "step": 6700
    },
    {
      "epoch": 1.7400310719834282,
      "grad_norm": 0.7851256728172302,
      "learning_rate": 2.103400655964095e-05,
      "loss": 0.3065,
      "step": 6720
    },
    {
      "epoch": 1.7452097358881409,
      "grad_norm": 0.23404143750667572,
      "learning_rate": 2.09476954945624e-05,
      "loss": 0.1956,
      "step": 6740
    },
    {
      "epoch": 1.7503883997928535,
      "grad_norm": 0.19727736711502075,
      "learning_rate": 2.086138442948386e-05,
      "loss": 0.3642,
      "step": 6760
    },
    {
      "epoch": 1.755567063697566,
      "grad_norm": 0.26446762681007385,
      "learning_rate": 2.0775073364405317e-05,
      "loss": 0.2614,
      "step": 6780
    },
    {
      "epoch": 1.7607457276022787,
      "grad_norm": 0.3105219602584839,
      "learning_rate": 2.0688762299326777e-05,
      "loss": 0.3125,
      "step": 6800
    },
    {
      "epoch": 1.7659243915069913,
      "grad_norm": 0.5838945508003235,
      "learning_rate": 2.0602451234248233e-05,
      "loss": 0.2128,
      "step": 6820
    },
    {
      "epoch": 1.7711030554117038,
      "grad_norm": 0.3489389717578888,
      "learning_rate": 2.051614016916969e-05,
      "loss": 0.2459,
      "step": 6840
    },
    {
      "epoch": 1.7762817193164162,
      "grad_norm": 0.21004430949687958,
      "learning_rate": 2.0429829104091145e-05,
      "loss": 0.2871,
      "step": 6860
    },
    {
      "epoch": 1.781460383221129,
      "grad_norm": 0.3586350083351135,
      "learning_rate": 2.03435180390126e-05,
      "loss": 0.1876,
      "step": 6880
    },
    {
      "epoch": 1.7866390471258415,
      "grad_norm": 1.5739222764968872,
      "learning_rate": 2.0257206973934058e-05,
      "loss": 0.51,
      "step": 6900
    },
    {
      "epoch": 1.791817711030554,
      "grad_norm": 1.3190467357635498,
      "learning_rate": 2.0170895908855517e-05,
      "loss": 0.248,
      "step": 6920
    },
    {
      "epoch": 1.7969963749352666,
      "grad_norm": 1.1998502016067505,
      "learning_rate": 2.0084584843776973e-05,
      "loss": 0.2413,
      "step": 6940
    },
    {
      "epoch": 1.8021750388399793,
      "grad_norm": 0.8048469424247742,
      "learning_rate": 1.9998273778698433e-05,
      "loss": 0.2549,
      "step": 6960
    },
    {
      "epoch": 1.8073537027446918,
      "grad_norm": 0.5955953001976013,
      "learning_rate": 1.9911962713619886e-05,
      "loss": 0.2458,
      "step": 6980
    },
    {
      "epoch": 1.8125323666494044,
      "grad_norm": 0.2842611074447632,
      "learning_rate": 1.9825651648541342e-05,
      "loss": 0.3728,
      "step": 7000
    },
    {
      "epoch": 1.817711030554117,
      "grad_norm": 0.29272302985191345,
      "learning_rate": 1.97393405834628e-05,
      "loss": 0.3097,
      "step": 7020
    },
    {
      "epoch": 1.8228896944588295,
      "grad_norm": 0.2697036862373352,
      "learning_rate": 1.9653029518384258e-05,
      "loss": 0.2696,
      "step": 7040
    },
    {
      "epoch": 1.8280683583635422,
      "grad_norm": 0.20303338766098022,
      "learning_rate": 1.9566718453305717e-05,
      "loss": 0.3188,
      "step": 7060
    },
    {
      "epoch": 1.8332470222682549,
      "grad_norm": 0.21544170379638672,
      "learning_rate": 1.948040738822717e-05,
      "loss": 0.2875,
      "step": 7080
    },
    {
      "epoch": 1.8384256861729673,
      "grad_norm": 0.20525333285331726,
      "learning_rate": 1.9394096323148626e-05,
      "loss": 0.2495,
      "step": 7100
    },
    {
      "epoch": 1.84360435007768,
      "grad_norm": 0.2195650041103363,
      "learning_rate": 1.9307785258070086e-05,
      "loss": 0.2611,
      "step": 7120
    },
    {
      "epoch": 1.8487830139823926,
      "grad_norm": 1.3291445970535278,
      "learning_rate": 1.9221474192991542e-05,
      "loss": 0.3518,
      "step": 7140
    },
    {
      "epoch": 1.853961677887105,
      "grad_norm": 0.47762376070022583,
      "learning_rate": 1.9135163127913e-05,
      "loss": 0.2769,
      "step": 7160
    },
    {
      "epoch": 1.8591403417918178,
      "grad_norm": 0.21632300317287445,
      "learning_rate": 1.9048852062834458e-05,
      "loss": 0.3161,
      "step": 7180
    },
    {
      "epoch": 1.8643190056965304,
      "grad_norm": 0.193900465965271,
      "learning_rate": 1.896254099775591e-05,
      "loss": 0.1866,
      "step": 7200
    },
    {
      "epoch": 1.8694976696012429,
      "grad_norm": 0.2617563009262085,
      "learning_rate": 1.887622993267737e-05,
      "loss": 0.3201,
      "step": 7220
    },
    {
      "epoch": 1.8746763335059553,
      "grad_norm": 0.15479843318462372,
      "learning_rate": 1.8789918867598826e-05,
      "loss": 0.269,
      "step": 7240
    },
    {
      "epoch": 1.8798549974106682,
      "grad_norm": 0.17535167932510376,
      "learning_rate": 1.8703607802520286e-05,
      "loss": 0.2137,
      "step": 7260
    },
    {
      "epoch": 1.8850336613153806,
      "grad_norm": 0.23476427793502808,
      "learning_rate": 1.8617296737441742e-05,
      "loss": 0.1796,
      "step": 7280
    },
    {
      "epoch": 1.890212325220093,
      "grad_norm": 0.3719208836555481,
      "learning_rate": 1.8530985672363198e-05,
      "loss": 0.2712,
      "step": 7300
    },
    {
      "epoch": 1.8953909891248057,
      "grad_norm": 0.17675812542438507,
      "learning_rate": 1.8444674607284654e-05,
      "loss": 0.2341,
      "step": 7320
    },
    {
      "epoch": 1.9005696530295184,
      "grad_norm": 1.2437083721160889,
      "learning_rate": 1.835836354220611e-05,
      "loss": 0.2632,
      "step": 7340
    },
    {
      "epoch": 1.9057483169342309,
      "grad_norm": 0.2352178543806076,
      "learning_rate": 1.827205247712757e-05,
      "loss": 0.2896,
      "step": 7360
    },
    {
      "epoch": 1.9109269808389435,
      "grad_norm": 1.4214651584625244,
      "learning_rate": 1.8185741412049026e-05,
      "loss": 0.3459,
      "step": 7380
    },
    {
      "epoch": 1.9161056447436562,
      "grad_norm": 0.3058021366596222,
      "learning_rate": 1.8099430346970483e-05,
      "loss": 0.2127,
      "step": 7400
    },
    {
      "epoch": 1.9212843086483686,
      "grad_norm": 0.2739493250846863,
      "learning_rate": 1.801311928189194e-05,
      "loss": 0.1536,
      "step": 7420
    },
    {
      "epoch": 1.9264629725530813,
      "grad_norm": 1.1102244853973389,
      "learning_rate": 1.7926808216813395e-05,
      "loss": 0.2336,
      "step": 7440
    },
    {
      "epoch": 1.931641636457794,
      "grad_norm": 0.33282485604286194,
      "learning_rate": 1.7840497151734855e-05,
      "loss": 0.2852,
      "step": 7460
    },
    {
      "epoch": 1.9368203003625064,
      "grad_norm": 0.23399238288402557,
      "learning_rate": 1.775418608665631e-05,
      "loss": 0.2799,
      "step": 7480
    },
    {
      "epoch": 1.941998964267219,
      "grad_norm": 0.14850345253944397,
      "learning_rate": 1.7667875021577767e-05,
      "loss": 0.1906,
      "step": 7500
    },
    {
      "epoch": 1.9471776281719317,
      "grad_norm": 0.22151054441928864,
      "learning_rate": 1.7581563956499226e-05,
      "loss": 0.3058,
      "step": 7520
    },
    {
      "epoch": 1.9523562920766442,
      "grad_norm": 0.31330832839012146,
      "learning_rate": 1.749525289142068e-05,
      "loss": 0.2926,
      "step": 7540
    },
    {
      "epoch": 1.9575349559813569,
      "grad_norm": 0.45594966411590576,
      "learning_rate": 1.740894182634214e-05,
      "loss": 0.204,
      "step": 7560
    },
    {
      "epoch": 1.9627136198860695,
      "grad_norm": 0.3343769311904907,
      "learning_rate": 1.7322630761263595e-05,
      "loss": 0.1888,
      "step": 7580
    },
    {
      "epoch": 1.967892283790782,
      "grad_norm": 0.3315966725349426,
      "learning_rate": 1.723631969618505e-05,
      "loss": 0.2594,
      "step": 7600
    },
    {
      "epoch": 1.9730709476954944,
      "grad_norm": 0.28564879298210144,
      "learning_rate": 1.715000863110651e-05,
      "loss": 0.2829,
      "step": 7620
    },
    {
      "epoch": 1.9782496116002073,
      "grad_norm": 17.96461296081543,
      "learning_rate": 1.7063697566027967e-05,
      "loss": 0.2632,
      "step": 7640
    },
    {
      "epoch": 1.9834282755049197,
      "grad_norm": 0.4628761112689972,
      "learning_rate": 1.6977386500949423e-05,
      "loss": 0.2932,
      "step": 7660
    },
    {
      "epoch": 1.9886069394096322,
      "grad_norm": 1.069676399230957,
      "learning_rate": 1.689107543587088e-05,
      "loss": 0.2591,
      "step": 7680
    },
    {
      "epoch": 1.9937856033143448,
      "grad_norm": 0.2821054756641388,
      "learning_rate": 1.6804764370792336e-05,
      "loss": 0.3305,
      "step": 7700
    },
    {
      "epoch": 1.9989642672190575,
      "grad_norm": 0.17619021236896515,
      "learning_rate": 1.6718453305713795e-05,
      "loss": 0.1865,
      "step": 7720
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.24525143206119537,
      "eval_runtime": 31.2625,
      "eval_samples_per_second": 27.477,
      "eval_steps_per_second": 3.455,
      "step": 7724
    },
    {
      "epoch": 2.00414293112377,
      "grad_norm": 0.2929278016090393,
      "learning_rate": 1.663214224063525e-05,
      "loss": 0.3243,
      "step": 7740
    },
    {
      "epoch": 2.009321595028483,
      "grad_norm": 0.14918598532676697,
      "learning_rate": 1.6545831175556707e-05,
      "loss": 0.2655,
      "step": 7760
    },
    {
      "epoch": 2.0145002589331953,
      "grad_norm": 0.5688777565956116,
      "learning_rate": 1.6459520110478164e-05,
      "loss": 0.3171,
      "step": 7780
    },
    {
      "epoch": 2.0196789228379077,
      "grad_norm": 0.32591089606285095,
      "learning_rate": 1.637320904539962e-05,
      "loss": 0.1908,
      "step": 7800
    },
    {
      "epoch": 2.0248575867426206,
      "grad_norm": 0.25188717246055603,
      "learning_rate": 1.628689798032108e-05,
      "loss": 0.2997,
      "step": 7820
    },
    {
      "epoch": 2.030036250647333,
      "grad_norm": 0.14261503517627716,
      "learning_rate": 1.6200586915242536e-05,
      "loss": 0.3817,
      "step": 7840
    },
    {
      "epoch": 2.0352149145520455,
      "grad_norm": 0.48775532841682434,
      "learning_rate": 1.6114275850163992e-05,
      "loss": 0.2274,
      "step": 7860
    },
    {
      "epoch": 2.040393578456758,
      "grad_norm": 0.374091237783432,
      "learning_rate": 1.6027964785085448e-05,
      "loss": 0.2451,
      "step": 7880
    },
    {
      "epoch": 2.045572242361471,
      "grad_norm": 0.3981737196445465,
      "learning_rate": 1.5941653720006904e-05,
      "loss": 0.3011,
      "step": 7900
    },
    {
      "epoch": 2.0507509062661833,
      "grad_norm": 0.5204510688781738,
      "learning_rate": 1.5855342654928364e-05,
      "loss": 0.2469,
      "step": 7920
    },
    {
      "epoch": 2.0559295701708957,
      "grad_norm": 0.5009440183639526,
      "learning_rate": 1.576903158984982e-05,
      "loss": 0.3737,
      "step": 7940
    },
    {
      "epoch": 2.0611082340756086,
      "grad_norm": 0.9192907214164734,
      "learning_rate": 1.5682720524771276e-05,
      "loss": 0.304,
      "step": 7960
    },
    {
      "epoch": 2.066286897980321,
      "grad_norm": 0.23442654311656952,
      "learning_rate": 1.5596409459692736e-05,
      "loss": 0.223,
      "step": 7980
    },
    {
      "epoch": 2.0714655618850335,
      "grad_norm": 0.1257234662771225,
      "learning_rate": 1.551009839461419e-05,
      "loss": 0.4476,
      "step": 8000
    },
    {
      "epoch": 2.0766442257897464,
      "grad_norm": 0.2106696367263794,
      "learning_rate": 1.5423787329535648e-05,
      "loss": 0.2232,
      "step": 8020
    },
    {
      "epoch": 2.081822889694459,
      "grad_norm": 0.4136849343776703,
      "learning_rate": 1.5337476264457104e-05,
      "loss": 0.1965,
      "step": 8040
    },
    {
      "epoch": 2.0870015535991713,
      "grad_norm": 0.36401018500328064,
      "learning_rate": 1.5251165199378562e-05,
      "loss": 0.2986,
      "step": 8060
    },
    {
      "epoch": 2.092180217503884,
      "grad_norm": 0.6004959940910339,
      "learning_rate": 1.5164854134300018e-05,
      "loss": 0.1998,
      "step": 8080
    },
    {
      "epoch": 2.0973588814085966,
      "grad_norm": 0.14347168803215027,
      "learning_rate": 1.5078543069221473e-05,
      "loss": 0.1951,
      "step": 8100
    },
    {
      "epoch": 2.102537545313309,
      "grad_norm": 1.8201234340667725,
      "learning_rate": 1.499223200414293e-05,
      "loss": 0.3404,
      "step": 8120
    },
    {
      "epoch": 2.107716209218022,
      "grad_norm": 2.0340397357940674,
      "learning_rate": 1.4905920939064389e-05,
      "loss": 0.3621,
      "step": 8140
    },
    {
      "epoch": 2.1128948731227344,
      "grad_norm": 0.2513582408428192,
      "learning_rate": 1.4819609873985846e-05,
      "loss": 0.2556,
      "step": 8160
    },
    {
      "epoch": 2.118073537027447,
      "grad_norm": 0.6325268149375916,
      "learning_rate": 1.4733298808907303e-05,
      "loss": 0.3753,
      "step": 8180
    },
    {
      "epoch": 2.1232522009321597,
      "grad_norm": 0.13514859974384308,
      "learning_rate": 1.464698774382876e-05,
      "loss": 0.1643,
      "step": 8200
    },
    {
      "epoch": 2.128430864836872,
      "grad_norm": 0.45168209075927734,
      "learning_rate": 1.4560676678750215e-05,
      "loss": 0.1904,
      "step": 8220
    },
    {
      "epoch": 2.1336095287415846,
      "grad_norm": 0.7161283493041992,
      "learning_rate": 1.4474365613671673e-05,
      "loss": 0.2904,
      "step": 8240
    },
    {
      "epoch": 2.138788192646297,
      "grad_norm": 0.22140072286128998,
      "learning_rate": 1.438805454859313e-05,
      "loss": 0.1796,
      "step": 8260
    },
    {
      "epoch": 2.14396685655101,
      "grad_norm": 0.3428267538547516,
      "learning_rate": 1.4301743483514587e-05,
      "loss": 0.2289,
      "step": 8280
    },
    {
      "epoch": 2.1491455204557224,
      "grad_norm": 0.3213019073009491,
      "learning_rate": 1.4215432418436045e-05,
      "loss": 0.156,
      "step": 8300
    },
    {
      "epoch": 2.154324184360435,
      "grad_norm": 0.4735472500324249,
      "learning_rate": 1.4129121353357503e-05,
      "loss": 0.2355,
      "step": 8320
    },
    {
      "epoch": 2.1595028482651477,
      "grad_norm": 0.7865894436836243,
      "learning_rate": 1.4042810288278957e-05,
      "loss": 0.2012,
      "step": 8340
    },
    {
      "epoch": 2.16468151216986,
      "grad_norm": 0.256498247385025,
      "learning_rate": 1.3956499223200415e-05,
      "loss": 0.2427,
      "step": 8360
    },
    {
      "epoch": 2.1698601760745726,
      "grad_norm": 0.38609856367111206,
      "learning_rate": 1.3870188158121871e-05,
      "loss": 0.2124,
      "step": 8380
    },
    {
      "epoch": 2.1750388399792855,
      "grad_norm": 0.4955911636352539,
      "learning_rate": 1.378387709304333e-05,
      "loss": 0.2394,
      "step": 8400
    },
    {
      "epoch": 2.180217503883998,
      "grad_norm": 0.27138185501098633,
      "learning_rate": 1.3697566027964787e-05,
      "loss": 0.1801,
      "step": 8420
    },
    {
      "epoch": 2.1853961677887104,
      "grad_norm": 0.3045790195465088,
      "learning_rate": 1.3611254962886243e-05,
      "loss": 0.4134,
      "step": 8440
    },
    {
      "epoch": 2.1905748316934233,
      "grad_norm": 0.4424099922180176,
      "learning_rate": 1.35249438978077e-05,
      "loss": 0.3878,
      "step": 8460
    },
    {
      "epoch": 2.1957534955981357,
      "grad_norm": 0.40658825635910034,
      "learning_rate": 1.3438632832729156e-05,
      "loss": 0.3764,
      "step": 8480
    },
    {
      "epoch": 2.200932159502848,
      "grad_norm": 0.4079881012439728,
      "learning_rate": 1.3352321767650614e-05,
      "loss": 0.2565,
      "step": 8500
    },
    {
      "epoch": 2.206110823407561,
      "grad_norm": 2.130075693130493,
      "learning_rate": 1.3266010702572071e-05,
      "loss": 0.3717,
      "step": 8520
    },
    {
      "epoch": 2.2112894873122735,
      "grad_norm": 0.7487932443618774,
      "learning_rate": 1.3179699637493528e-05,
      "loss": 0.3483,
      "step": 8540
    },
    {
      "epoch": 2.216468151216986,
      "grad_norm": 0.433955579996109,
      "learning_rate": 1.3093388572414984e-05,
      "loss": 0.3408,
      "step": 8560
    },
    {
      "epoch": 2.221646815121699,
      "grad_norm": 0.9689034223556519,
      "learning_rate": 1.300707750733644e-05,
      "loss": 0.4185,
      "step": 8580
    },
    {
      "epoch": 2.2268254790264113,
      "grad_norm": 0.2065296322107315,
      "learning_rate": 1.2920766442257898e-05,
      "loss": 0.3727,
      "step": 8600
    },
    {
      "epoch": 2.2320041429311237,
      "grad_norm": 0.5922778844833374,
      "learning_rate": 1.2834455377179356e-05,
      "loss": 0.1919,
      "step": 8620
    },
    {
      "epoch": 2.237182806835836,
      "grad_norm": 0.7543306946754456,
      "learning_rate": 1.2748144312100812e-05,
      "loss": 0.3192,
      "step": 8640
    },
    {
      "epoch": 2.242361470740549,
      "grad_norm": 0.4975000321865082,
      "learning_rate": 1.266183324702227e-05,
      "loss": 0.4172,
      "step": 8660
    },
    {
      "epoch": 2.2475401346452615,
      "grad_norm": 0.18206018209457397,
      "learning_rate": 1.2575522181943724e-05,
      "loss": 0.3714,
      "step": 8680
    },
    {
      "epoch": 2.252718798549974,
      "grad_norm": 0.34804224967956543,
      "learning_rate": 1.2489211116865182e-05,
      "loss": 0.2225,
      "step": 8700
    },
    {
      "epoch": 2.257897462454687,
      "grad_norm": 0.49364641308784485,
      "learning_rate": 1.240290005178664e-05,
      "loss": 0.2232,
      "step": 8720
    },
    {
      "epoch": 2.2630761263593993,
      "grad_norm": 0.20968729257583618,
      "learning_rate": 1.2316588986708096e-05,
      "loss": 0.2739,
      "step": 8740
    },
    {
      "epoch": 2.2682547902641117,
      "grad_norm": 0.6046320199966431,
      "learning_rate": 1.2230277921629552e-05,
      "loss": 0.2622,
      "step": 8760
    },
    {
      "epoch": 2.2734334541688246,
      "grad_norm": 0.34591391682624817,
      "learning_rate": 1.214396685655101e-05,
      "loss": 0.2267,
      "step": 8780
    },
    {
      "epoch": 2.278612118073537,
      "grad_norm": 0.5354174971580505,
      "learning_rate": 1.2057655791472468e-05,
      "loss": 0.1493,
      "step": 8800
    },
    {
      "epoch": 2.2837907819782495,
      "grad_norm": 0.49248582124710083,
      "learning_rate": 1.1971344726393924e-05,
      "loss": 0.2329,
      "step": 8820
    },
    {
      "epoch": 2.2889694458829624,
      "grad_norm": 0.39922383427619934,
      "learning_rate": 1.188503366131538e-05,
      "loss": 0.2814,
      "step": 8840
    },
    {
      "epoch": 2.294148109787675,
      "grad_norm": 0.14367201924324036,
      "learning_rate": 1.1798722596236838e-05,
      "loss": 0.1811,
      "step": 8860
    },
    {
      "epoch": 2.2993267736923872,
      "grad_norm": 1.0322359800338745,
      "learning_rate": 1.1716727084412223e-05,
      "loss": 0.2839,
      "step": 8880
    },
    {
      "epoch": 2.3045054375971,
      "grad_norm": 0.20649287104606628,
      "learning_rate": 1.1630416019333678e-05,
      "loss": 0.1629,
      "step": 8900
    },
    {
      "epoch": 2.3096841015018126,
      "grad_norm": 0.6177270412445068,
      "learning_rate": 1.1544104954255136e-05,
      "loss": 0.4151,
      "step": 8920
    },
    {
      "epoch": 2.314862765406525,
      "grad_norm": 0.10415218770503998,
      "learning_rate": 1.1457793889176594e-05,
      "loss": 0.2655,
      "step": 8940
    },
    {
      "epoch": 2.320041429311238,
      "grad_norm": 0.399181991815567,
      "learning_rate": 1.137148282409805e-05,
      "loss": 0.2125,
      "step": 8960
    },
    {
      "epoch": 2.3252200932159504,
      "grad_norm": 0.34739547967910767,
      "learning_rate": 1.1285171759019508e-05,
      "loss": 0.2399,
      "step": 8980
    },
    {
      "epoch": 2.330398757120663,
      "grad_norm": 0.31703728437423706,
      "learning_rate": 1.1198860693940964e-05,
      "loss": 0.2559,
      "step": 9000
    },
    {
      "epoch": 2.3355774210253752,
      "grad_norm": 0.15122662484645844,
      "learning_rate": 1.111254962886242e-05,
      "loss": 0.2128,
      "step": 9020
    },
    {
      "epoch": 2.340756084930088,
      "grad_norm": 0.37811997532844543,
      "learning_rate": 1.1026238563783878e-05,
      "loss": 0.3769,
      "step": 9040
    },
    {
      "epoch": 2.3459347488348006,
      "grad_norm": 0.6302147507667542,
      "learning_rate": 1.0939927498705336e-05,
      "loss": 0.2047,
      "step": 9060
    },
    {
      "epoch": 2.351113412739513,
      "grad_norm": 1.4789258241653442,
      "learning_rate": 1.0853616433626792e-05,
      "loss": 0.2866,
      "step": 9080
    },
    {
      "epoch": 2.356292076644226,
      "grad_norm": 0.34609606862068176,
      "learning_rate": 1.0767305368548248e-05,
      "loss": 0.191,
      "step": 9100
    },
    {
      "epoch": 2.3614707405489384,
      "grad_norm": 0.5439001321792603,
      "learning_rate": 1.0680994303469704e-05,
      "loss": 0.2499,
      "step": 9120
    },
    {
      "epoch": 2.366649404453651,
      "grad_norm": 0.9490929245948792,
      "learning_rate": 1.0594683238391162e-05,
      "loss": 0.3617,
      "step": 9140
    },
    {
      "epoch": 2.3718280683583637,
      "grad_norm": 1.0234419107437134,
      "learning_rate": 1.050837217331262e-05,
      "loss": 0.2812,
      "step": 9160
    },
    {
      "epoch": 2.377006732263076,
      "grad_norm": 0.3213859796524048,
      "learning_rate": 1.0422061108234075e-05,
      "loss": 0.3101,
      "step": 9180
    },
    {
      "epoch": 2.3821853961677886,
      "grad_norm": 0.5499028563499451,
      "learning_rate": 1.0335750043155533e-05,
      "loss": 0.4104,
      "step": 9200
    },
    {
      "epoch": 2.3873640600725015,
      "grad_norm": 0.18397027254104614,
      "learning_rate": 1.024943897807699e-05,
      "loss": 0.3452,
      "step": 9220
    },
    {
      "epoch": 2.392542723977214,
      "grad_norm": 1.2756476402282715,
      "learning_rate": 1.0163127912998447e-05,
      "loss": 0.2618,
      "step": 9240
    },
    {
      "epoch": 2.3977213878819263,
      "grad_norm": 0.26398879289627075,
      "learning_rate": 1.0076816847919905e-05,
      "loss": 0.4748,
      "step": 9260
    },
    {
      "epoch": 2.4029000517866392,
      "grad_norm": 0.27952197194099426,
      "learning_rate": 9.99050578284136e-06,
      "loss": 0.2412,
      "step": 9280
    },
    {
      "epoch": 2.4080787156913517,
      "grad_norm": 0.2417363077402115,
      "learning_rate": 9.904194717762817e-06,
      "loss": 0.2757,
      "step": 9300
    },
    {
      "epoch": 2.413257379596064,
      "grad_norm": 0.22533781826496124,
      "learning_rate": 9.817883652684275e-06,
      "loss": 0.3037,
      "step": 9320
    },
    {
      "epoch": 2.418436043500777,
      "grad_norm": 0.21757926046848297,
      "learning_rate": 9.731572587605733e-06,
      "loss": 0.1483,
      "step": 9340
    },
    {
      "epoch": 2.4236147074054895,
      "grad_norm": 1.3234729766845703,
      "learning_rate": 9.645261522527189e-06,
      "loss": 0.2149,
      "step": 9360
    },
    {
      "epoch": 2.428793371310202,
      "grad_norm": 0.29498645663261414,
      "learning_rate": 9.558950457448645e-06,
      "loss": 0.1881,
      "step": 9380
    },
    {
      "epoch": 2.4339720352149143,
      "grad_norm": 0.36360347270965576,
      "learning_rate": 9.472639392370103e-06,
      "loss": 0.2929,
      "step": 9400
    },
    {
      "epoch": 2.4391506991196272,
      "grad_norm": 0.15952356159687042,
      "learning_rate": 9.386328327291559e-06,
      "loss": 0.1504,
      "step": 9420
    },
    {
      "epoch": 2.4443293630243397,
      "grad_norm": 0.22415682673454285,
      "learning_rate": 9.300017262213017e-06,
      "loss": 0.2994,
      "step": 9440
    },
    {
      "epoch": 2.449508026929052,
      "grad_norm": 0.3758227229118347,
      "learning_rate": 9.213706197134473e-06,
      "loss": 0.2317,
      "step": 9460
    },
    {
      "epoch": 2.454686690833765,
      "grad_norm": 0.22654736042022705,
      "learning_rate": 9.12739513205593e-06,
      "loss": 0.3303,
      "step": 9480
    },
    {
      "epoch": 2.4598653547384774,
      "grad_norm": 0.2135101854801178,
      "learning_rate": 9.041084066977387e-06,
      "loss": 0.2015,
      "step": 9500
    },
    {
      "epoch": 2.46504401864319,
      "grad_norm": 0.4311269521713257,
      "learning_rate": 8.954773001898843e-06,
      "loss": 0.1944,
      "step": 9520
    },
    {
      "epoch": 2.470222682547903,
      "grad_norm": 1.4625710248947144,
      "learning_rate": 8.868461936820301e-06,
      "loss": 0.2285,
      "step": 9540
    },
    {
      "epoch": 2.4754013464526152,
      "grad_norm": 0.46088775992393494,
      "learning_rate": 8.782150871741757e-06,
      "loss": 0.2018,
      "step": 9560
    },
    {
      "epoch": 2.4805800103573277,
      "grad_norm": 0.11525082588195801,
      "learning_rate": 8.695839806663214e-06,
      "loss": 0.1828,
      "step": 9580
    },
    {
      "epoch": 2.4857586742620406,
      "grad_norm": 0.2859494984149933,
      "learning_rate": 8.609528741584672e-06,
      "loss": 0.4243,
      "step": 9600
    },
    {
      "epoch": 2.490937338166753,
      "grad_norm": 0.2877313792705536,
      "learning_rate": 8.52321767650613e-06,
      "loss": 0.2917,
      "step": 9620
    },
    {
      "epoch": 2.4961160020714654,
      "grad_norm": 0.340677946805954,
      "learning_rate": 8.436906611427586e-06,
      "loss": 0.2628,
      "step": 9640
    },
    {
      "epoch": 2.501294665976178,
      "grad_norm": 1.8399534225463867,
      "learning_rate": 8.350595546349042e-06,
      "loss": 0.3103,
      "step": 9660
    },
    {
      "epoch": 2.5064733298808908,
      "grad_norm": 0.34409940242767334,
      "learning_rate": 8.2642844812705e-06,
      "loss": 0.2714,
      "step": 9680
    },
    {
      "epoch": 2.511651993785603,
      "grad_norm": 0.16428682208061218,
      "learning_rate": 8.177973416191956e-06,
      "loss": 0.2515,
      "step": 9700
    },
    {
      "epoch": 2.516830657690316,
      "grad_norm": 0.19999150931835175,
      "learning_rate": 8.091662351113414e-06,
      "loss": 0.283,
      "step": 9720
    },
    {
      "epoch": 2.5220093215950286,
      "grad_norm": 0.24805818498134613,
      "learning_rate": 8.00535128603487e-06,
      "loss": 0.4373,
      "step": 9740
    },
    {
      "epoch": 2.527187985499741,
      "grad_norm": 0.7238517999649048,
      "learning_rate": 7.919040220956326e-06,
      "loss": 0.2211,
      "step": 9760
    },
    {
      "epoch": 2.5323666494044534,
      "grad_norm": 0.63775634765625,
      "learning_rate": 7.832729155877784e-06,
      "loss": 0.2662,
      "step": 9780
    },
    {
      "epoch": 2.5375453133091663,
      "grad_norm": 0.4213234782218933,
      "learning_rate": 7.746418090799242e-06,
      "loss": 0.2287,
      "step": 9800
    },
    {
      "epoch": 2.5427239772138788,
      "grad_norm": 0.446313738822937,
      "learning_rate": 7.660107025720698e-06,
      "loss": 0.2894,
      "step": 9820
    },
    {
      "epoch": 2.5479026411185917,
      "grad_norm": 0.5389586687088013,
      "learning_rate": 7.573795960642155e-06,
      "loss": 0.2858,
      "step": 9840
    },
    {
      "epoch": 2.553081305023304,
      "grad_norm": 0.12202479690313339,
      "learning_rate": 7.487484895563611e-06,
      "loss": 0.2587,
      "step": 9860
    },
    {
      "epoch": 2.5582599689280165,
      "grad_norm": 0.9049175381660461,
      "learning_rate": 7.401173830485068e-06,
      "loss": 0.3227,
      "step": 9880
    },
    {
      "epoch": 2.563438632832729,
      "grad_norm": 0.594632625579834,
      "learning_rate": 7.314862765406525e-06,
      "loss": 0.2788,
      "step": 9900
    },
    {
      "epoch": 2.568617296737442,
      "grad_norm": 0.3123483955860138,
      "learning_rate": 7.228551700327982e-06,
      "loss": 0.3234,
      "step": 9920
    },
    {
      "epoch": 2.5737959606421543,
      "grad_norm": 0.41569310426712036,
      "learning_rate": 7.1422406352494395e-06,
      "loss": 0.1565,
      "step": 9940
    },
    {
      "epoch": 2.5789746245468668,
      "grad_norm": 0.1473432034254074,
      "learning_rate": 7.0559295701708965e-06,
      "loss": 0.2133,
      "step": 9960
    },
    {
      "epoch": 2.5841532884515797,
      "grad_norm": 0.7106463313102722,
      "learning_rate": 6.969618505092353e-06,
      "loss": 0.3585,
      "step": 9980
    },
    {
      "epoch": 2.589331952356292,
      "grad_norm": 0.33179426193237305,
      "learning_rate": 6.88330744001381e-06,
      "loss": 0.2037,
      "step": 10000
    },
    {
      "epoch": 2.5945106162610045,
      "grad_norm": 0.4931439161300659,
      "learning_rate": 6.796996374935268e-06,
      "loss": 0.2855,
      "step": 10020
    },
    {
      "epoch": 2.599689280165717,
      "grad_norm": 0.8946104645729065,
      "learning_rate": 6.710685309856724e-06,
      "loss": 0.3285,
      "step": 10040
    },
    {
      "epoch": 2.60486794407043,
      "grad_norm": 0.4633861184120178,
      "learning_rate": 6.624374244778181e-06,
      "loss": 0.3294,
      "step": 10060
    },
    {
      "epoch": 2.6100466079751423,
      "grad_norm": 0.08763065934181213,
      "learning_rate": 6.538063179699639e-06,
      "loss": 0.4061,
      "step": 10080
    },
    {
      "epoch": 2.615225271879855,
      "grad_norm": 0.5944342017173767,
      "learning_rate": 6.451752114621094e-06,
      "loss": 0.2807,
      "step": 10100
    },
    {
      "epoch": 2.6204039357845677,
      "grad_norm": 0.3005553185939789,
      "learning_rate": 6.365441049542552e-06,
      "loss": 0.1968,
      "step": 10120
    },
    {
      "epoch": 2.62558259968928,
      "grad_norm": 0.41935986280441284,
      "learning_rate": 6.279129984464009e-06,
      "loss": 0.2592,
      "step": 10140
    },
    {
      "epoch": 2.6307612635939925,
      "grad_norm": 0.4903582036495209,
      "learning_rate": 6.192818919385465e-06,
      "loss": 0.2198,
      "step": 10160
    },
    {
      "epoch": 2.6359399274987054,
      "grad_norm": 0.2427578568458557,
      "learning_rate": 6.106507854306923e-06,
      "loss": 0.3041,
      "step": 10180
    },
    {
      "epoch": 2.641118591403418,
      "grad_norm": 0.514762282371521,
      "learning_rate": 6.020196789228379e-06,
      "loss": 0.3631,
      "step": 10200
    },
    {
      "epoch": 2.6462972553081308,
      "grad_norm": 0.1709321290254593,
      "learning_rate": 5.933885724149836e-06,
      "loss": 0.2623,
      "step": 10220
    },
    {
      "epoch": 2.651475919212843,
      "grad_norm": 0.6028613448143005,
      "learning_rate": 5.847574659071293e-06,
      "loss": 0.2757,
      "step": 10240
    },
    {
      "epoch": 2.6566545831175556,
      "grad_norm": 0.28664258122444153,
      "learning_rate": 5.76126359399275e-06,
      "loss": 0.2727,
      "step": 10260
    },
    {
      "epoch": 2.661833247022268,
      "grad_norm": 0.3920838236808777,
      "learning_rate": 5.6749525289142065e-06,
      "loss": 0.2391,
      "step": 10280
    },
    {
      "epoch": 2.667011910926981,
      "grad_norm": 0.49677416682243347,
      "learning_rate": 5.588641463835664e-06,
      "loss": 0.1914,
      "step": 10300
    },
    {
      "epoch": 2.6721905748316934,
      "grad_norm": 0.3092459738254547,
      "learning_rate": 5.5023303987571214e-06,
      "loss": 0.2279,
      "step": 10320
    },
    {
      "epoch": 2.677369238736406,
      "grad_norm": 3.424436092376709,
      "learning_rate": 5.416019333678578e-06,
      "loss": 0.1828,
      "step": 10340
    },
    {
      "epoch": 2.6825479026411188,
      "grad_norm": 0.26686006784439087,
      "learning_rate": 5.329708268600035e-06,
      "loss": 0.3173,
      "step": 10360
    },
    {
      "epoch": 2.687726566545831,
      "grad_norm": 0.19932620227336884,
      "learning_rate": 5.243397203521492e-06,
      "loss": 0.2046,
      "step": 10380
    },
    {
      "epoch": 2.6929052304505436,
      "grad_norm": 0.3289427161216736,
      "learning_rate": 5.157086138442949e-06,
      "loss": 0.2562,
      "step": 10400
    },
    {
      "epoch": 2.698083894355256,
      "grad_norm": 0.3868781328201294,
      "learning_rate": 5.070775073364406e-06,
      "loss": 0.2192,
      "step": 10420
    },
    {
      "epoch": 2.703262558259969,
      "grad_norm": 1.160396695137024,
      "learning_rate": 4.984464008285863e-06,
      "loss": 0.3111,
      "step": 10440
    },
    {
      "epoch": 2.7084412221646814,
      "grad_norm": 0.5463848114013672,
      "learning_rate": 4.89815294320732e-06,
      "loss": 0.2096,
      "step": 10460
    },
    {
      "epoch": 2.7136198860693943,
      "grad_norm": 0.550800085067749,
      "learning_rate": 4.811841878128776e-06,
      "loss": 0.3186,
      "step": 10480
    },
    {
      "epoch": 2.7187985499741067,
      "grad_norm": 0.49416452646255493,
      "learning_rate": 4.725530813050233e-06,
      "loss": 0.1635,
      "step": 10500
    },
    {
      "epoch": 2.723977213878819,
      "grad_norm": 0.3310086727142334,
      "learning_rate": 4.63921974797169e-06,
      "loss": 0.25,
      "step": 10520
    },
    {
      "epoch": 2.7291558777835316,
      "grad_norm": 0.20408445596694946,
      "learning_rate": 4.552908682893147e-06,
      "loss": 0.1916,
      "step": 10540
    },
    {
      "epoch": 2.7343345416882445,
      "grad_norm": 0.4500117301940918,
      "learning_rate": 4.466597617814604e-06,
      "loss": 0.2076,
      "step": 10560
    },
    {
      "epoch": 2.739513205592957,
      "grad_norm": 0.13194218277931213,
      "learning_rate": 4.380286552736061e-06,
      "loss": 0.3937,
      "step": 10580
    },
    {
      "epoch": 2.74469186949767,
      "grad_norm": 0.3175906836986542,
      "learning_rate": 4.293975487657518e-06,
      "loss": 0.2872,
      "step": 10600
    },
    {
      "epoch": 2.7498705334023823,
      "grad_norm": 0.7143405079841614,
      "learning_rate": 4.207664422578974e-06,
      "loss": 0.2771,
      "step": 10620
    },
    {
      "epoch": 2.7550491973070947,
      "grad_norm": 0.2707631289958954,
      "learning_rate": 4.121353357500432e-06,
      "loss": 0.3911,
      "step": 10640
    },
    {
      "epoch": 2.760227861211807,
      "grad_norm": 0.4819261431694031,
      "learning_rate": 4.0350422924218885e-06,
      "loss": 0.3206,
      "step": 10660
    },
    {
      "epoch": 2.76540652511652,
      "grad_norm": 0.18884412944316864,
      "learning_rate": 3.9487312273433455e-06,
      "loss": 0.3167,
      "step": 10680
    },
    {
      "epoch": 2.7705851890212325,
      "grad_norm": 0.3822418451309204,
      "learning_rate": 3.8624201622648026e-06,
      "loss": 0.2113,
      "step": 10700
    },
    {
      "epoch": 2.775763852925945,
      "grad_norm": 0.4589531123638153,
      "learning_rate": 3.7761090971862596e-06,
      "loss": 0.3472,
      "step": 10720
    },
    {
      "epoch": 2.780942516830658,
      "grad_norm": 0.5361295342445374,
      "learning_rate": 3.689798032107716e-06,
      "loss": 0.2137,
      "step": 10740
    },
    {
      "epoch": 2.7861211807353703,
      "grad_norm": 0.9044303297996521,
      "learning_rate": 3.6034869670291732e-06,
      "loss": 0.2803,
      "step": 10760
    },
    {
      "epoch": 2.7912998446400827,
      "grad_norm": 1.5988355875015259,
      "learning_rate": 3.5171759019506307e-06,
      "loss": 0.24,
      "step": 10780
    },
    {
      "epoch": 2.796478508544795,
      "grad_norm": 0.30712607502937317,
      "learning_rate": 3.4308648368720873e-06,
      "loss": 0.2924,
      "step": 10800
    },
    {
      "epoch": 2.801657172449508,
      "grad_norm": 0.2609383761882782,
      "learning_rate": 3.344553771793544e-06,
      "loss": 0.1495,
      "step": 10820
    },
    {
      "epoch": 2.8068358363542205,
      "grad_norm": 0.43424543738365173,
      "learning_rate": 3.2582427067150014e-06,
      "loss": 0.1659,
      "step": 10840
    },
    {
      "epoch": 2.8120145002589334,
      "grad_norm": 1.934617042541504,
      "learning_rate": 3.171931641636458e-06,
      "loss": 0.2527,
      "step": 10860
    },
    {
      "epoch": 2.817193164163646,
      "grad_norm": 0.2476944476366043,
      "learning_rate": 3.0856205765579146e-06,
      "loss": 0.1815,
      "step": 10880
    },
    {
      "epoch": 2.8223718280683583,
      "grad_norm": 0.3459109663963318,
      "learning_rate": 2.999309511479372e-06,
      "loss": 0.2184,
      "step": 10900
    },
    {
      "epoch": 2.8275504919730707,
      "grad_norm": 0.3350335359573364,
      "learning_rate": 2.9129984464008287e-06,
      "loss": 0.2355,
      "step": 10920
    },
    {
      "epoch": 2.8327291558777836,
      "grad_norm": 0.1731865555047989,
      "learning_rate": 2.8266873813222857e-06,
      "loss": 0.1737,
      "step": 10940
    },
    {
      "epoch": 2.837907819782496,
      "grad_norm": 0.3091031610965729,
      "learning_rate": 2.7403763162437427e-06,
      "loss": 0.2731,
      "step": 10960
    },
    {
      "epoch": 2.843086483687209,
      "grad_norm": 0.22944502532482147,
      "learning_rate": 2.6540652511651994e-06,
      "loss": 0.1651,
      "step": 10980
    },
    {
      "epoch": 2.8482651475919214,
      "grad_norm": 0.3457893133163452,
      "learning_rate": 2.5677541860866564e-06,
      "loss": 0.2906,
      "step": 11000
    },
    {
      "epoch": 2.853443811496634,
      "grad_norm": 0.262829065322876,
      "learning_rate": 2.4814431210081134e-06,
      "loss": 0.1611,
      "step": 11020
    },
    {
      "epoch": 2.8586224754013463,
      "grad_norm": 0.6024414300918579,
      "learning_rate": 2.3951320559295705e-06,
      "loss": 0.2068,
      "step": 11040
    },
    {
      "epoch": 2.863801139306059,
      "grad_norm": 0.5490036010742188,
      "learning_rate": 2.3088209908510275e-06,
      "loss": 0.3953,
      "step": 11060
    },
    {
      "epoch": 2.8689798032107716,
      "grad_norm": 0.4013100564479828,
      "learning_rate": 2.222509925772484e-06,
      "loss": 0.2463,
      "step": 11080
    },
    {
      "epoch": 2.874158467115484,
      "grad_norm": 0.5643383264541626,
      "learning_rate": 2.136198860693941e-06,
      "loss": 0.1776,
      "step": 11100
    },
    {
      "epoch": 2.879337131020197,
      "grad_norm": 0.4000108242034912,
      "learning_rate": 2.0498877956153977e-06,
      "loss": 0.2098,
      "step": 11120
    },
    {
      "epoch": 2.8845157949249094,
      "grad_norm": 0.31055164337158203,
      "learning_rate": 1.9635767305368548e-06,
      "loss": 0.2465,
      "step": 11140
    },
    {
      "epoch": 2.889694458829622,
      "grad_norm": 0.21633577346801758,
      "learning_rate": 1.877265665458312e-06,
      "loss": 0.2688,
      "step": 11160
    },
    {
      "epoch": 2.8948731227343343,
      "grad_norm": 1.5944488048553467,
      "learning_rate": 1.7909546003797686e-06,
      "loss": 0.2127,
      "step": 11180
    },
    {
      "epoch": 2.900051786639047,
      "grad_norm": 0.3886249363422394,
      "learning_rate": 1.7046435353012257e-06,
      "loss": 0.1712,
      "step": 11200
    },
    {
      "epoch": 2.9052304505437596,
      "grad_norm": 2.5974056720733643,
      "learning_rate": 1.6183324702226825e-06,
      "loss": 0.4115,
      "step": 11220
    },
    {
      "epoch": 2.9104091144484725,
      "grad_norm": 1.4686886072158813,
      "learning_rate": 1.5320214051441395e-06,
      "loss": 0.1923,
      "step": 11240
    },
    {
      "epoch": 2.915587778353185,
      "grad_norm": 0.9545495510101318,
      "learning_rate": 1.4457103400655964e-06,
      "loss": 0.2822,
      "step": 11260
    },
    {
      "epoch": 2.9207664422578974,
      "grad_norm": 0.36713603138923645,
      "learning_rate": 1.3593992749870534e-06,
      "loss": 0.3033,
      "step": 11280
    },
    {
      "epoch": 2.92594510616261,
      "grad_norm": 0.5118230581283569,
      "learning_rate": 1.2730882099085102e-06,
      "loss": 0.157,
      "step": 11300
    },
    {
      "epoch": 2.9311237700673227,
      "grad_norm": 0.24979336559772491,
      "learning_rate": 1.1867771448299673e-06,
      "loss": 0.2377,
      "step": 11320
    },
    {
      "epoch": 2.936302433972035,
      "grad_norm": 0.6996898055076599,
      "learning_rate": 1.1004660797514243e-06,
      "loss": 0.3398,
      "step": 11340
    },
    {
      "epoch": 2.941481097876748,
      "grad_norm": 0.4390474855899811,
      "learning_rate": 1.0141550146728811e-06,
      "loss": 0.3625,
      "step": 11360
    },
    {
      "epoch": 2.9466597617814605,
      "grad_norm": 0.2893366515636444,
      "learning_rate": 9.27843949594338e-07,
      "loss": 0.3773,
      "step": 11380
    },
    {
      "epoch": 2.951838425686173,
      "grad_norm": 0.6177000403404236,
      "learning_rate": 8.415328845157949e-07,
      "loss": 0.2243,
      "step": 11400
    },
    {
      "epoch": 2.9570170895908854,
      "grad_norm": 0.17861516773700714,
      "learning_rate": 7.552218194372519e-07,
      "loss": 0.2245,
      "step": 11420
    },
    {
      "epoch": 2.9621957534955983,
      "grad_norm": 0.4894213378429413,
      "learning_rate": 6.689107543587088e-07,
      "loss": 0.2042,
      "step": 11440
    },
    {
      "epoch": 2.9673744174003107,
      "grad_norm": 0.47240349650382996,
      "learning_rate": 5.825996892801658e-07,
      "loss": 0.3055,
      "step": 11460
    },
    {
      "epoch": 2.972553081305023,
      "grad_norm": 0.21855655312538147,
      "learning_rate": 4.962886242016227e-07,
      "loss": 0.1906,
      "step": 11480
    },
    {
      "epoch": 2.977731745209736,
      "grad_norm": 0.31959298253059387,
      "learning_rate": 4.099775591230796e-07,
      "loss": 0.1993,
      "step": 11500
    },
    {
      "epoch": 2.9829104091144485,
      "grad_norm": 0.29315561056137085,
      "learning_rate": 3.2366649404453654e-07,
      "loss": 0.3737,
      "step": 11520
    },
    {
      "epoch": 2.988089073019161,
      "grad_norm": 0.14027008414268494,
      "learning_rate": 2.3735542896599344e-07,
      "loss": 0.3422,
      "step": 11540
    },
    {
      "epoch": 2.9932677369238734,
      "grad_norm": 0.18989597260951996,
      "learning_rate": 1.5104436388745037e-07,
      "loss": 0.3381,
      "step": 11560
    },
    {
      "epoch": 2.9984464008285863,
      "grad_norm": 0.7339795231819153,
      "learning_rate": 6.47332988089073e-08,
      "loss": 0.2231,
      "step": 11580
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.24323676526546478,
      "eval_runtime": 31.2748,
      "eval_samples_per_second": 27.466,
      "eval_steps_per_second": 3.453,
      "step": 11586
    }
  ],
  "logging_steps": 20,
  "max_steps": 11586,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4234887833255936e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
